{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRpK6EuaxAOd"
   },
   "source": [
    "# Lab 3: Digital imagery and image processing\n",
    "\n",
    "**Purpose:** The purpose of this lab is to demonstrate concepts of digital image processing.  You will be introduced to methods for image smoothing, sharpening, edge detection, morphological processing, texture analysis, resampling and reprojection.  At the completion of the lab, you will be able to identify image processing operators that may be useful in extracting information of interest for your image analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxAQMzws1L3C"
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import geemap\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmLQLlUR1QR6"
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5pt1kImxbxh"
   },
   "source": [
    "## Digital image visualization\n",
    "\n",
    "You've learned about how an image stores pixel data in each band as DNs and how the pixels are organized spatially.  When you add an image to the map, Earth Engine handles the spatial display for you by recognizing the projection and putting all the pixels in the right place.  However, you must specify how to stretch the DNs to make an 8-bit display image (e.g. the min and max visualization parameters).  Specifying min and max applies (where $DN'$ is the displayed value):\n",
    "\n",
    "$DN' = (DN - min) * 255 / (max - min)$\n",
    "\n",
    "This visualization process is linear, we can apply transformations on the displayed values to highlight specific features of the image or values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekJ8Q6dfYyrR"
   },
   "outputs": [],
   "source": [
    "# load in a Landsat 8 image directly \n",
    "# this is the image we will be using for processing\n",
    "image = (\n",
    "    ee.Image('LANDSAT/LC08/C01/T1_SR/LC08_044034_20140318')\n",
    "    .select(\"B[1-7]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VAjK-Hv83UK"
   },
   "source": [
    "Some of the image processing we are going to explore requires us to \"force\" Earth Engine to process at a specific projection and scale so we are going to set the image projection to a variable for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItwfAjq58s-5"
   },
   "outputs": [],
   "source": [
    "# extract out the projection information\n",
    "proj = image.projection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK8nkRTI19uz"
   },
   "source": [
    "### Gamma correction\n",
    "\n",
    "The Gamma correction is a nonlinear operation used to scale the DN values for visualization. The gamma correction can be applied mathematically ($DN' = DN^\\gamma$), however, we can apply it simply providing the `gamma` keyword for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfNQbfqO2AU5"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "# Display gamma stretches of the input image.\n",
    "Map.addLayer(image.visualize(bands=[\"B7\",\"B5\",\"B3\"], min=0, max=5500, gamma=0.5), {}, 'gamma = 0.5');\n",
    "Map.addLayer(image.visualize(bands=[\"B7\",\"B5\",\"B3\"], min=0, max=5500, gamma=1.5), {}, 'gamma = 1.5');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "311i4Iubz0GK"
   },
   "source": [
    "Note that gamma is supplied as an argument to `image.visualize()` so that you can click on the map to see the difference in pixel values (try it!).  It's possible to specify gamma, min and max to achieve other unique visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQ1wEiZY3419"
   },
   "source": [
    "### Histogram equalization\n",
    "\n",
    "Histogram equalization is a method in image processing of contrast adjustment using the image's histogram.\n",
    "\n",
    "To apply a histogram equalization stretch, use the `sldStyle()` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rXZ96zb0DTD"
   },
   "outputs": [],
   "source": [
    "# Define a RasterSymbolizer element with '_enhance_' for a placeholder.\n",
    "histogram_sld = \"\"\"\n",
    "  <RasterSymbolizer>\n",
    "    <ContrastEnhancement><Histogram/></ContrastEnhancement>\n",
    "    <ChannelSelection>\n",
    "      <RedChannel>\n",
    "        <SourceChannelName>B7</SourceChannelName>\n",
    "      </RedChannel>\n",
    "      <GreenChannel>\n",
    "        <SourceChannelName>B5</SourceChannelName>\n",
    "      </GreenChannel>\n",
    "      <BlueChannel>\n",
    "        <SourceChannelName>B3</SourceChannelName>\n",
    "      </BlueChannel>\n",
    "    </ChannelSelection>\n",
    "  </RasterSymbolizer>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KN30AbRz4cm4"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "# Display visualization stretches of the input image.\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(image.sldStyle(histogram_sld), {}, 'Equalized');\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfbQd1RmxiTx"
   },
   "source": [
    "## Band math\n",
    "\n",
    "Band math can be performed using operators like `add()` and `subtract()`, but for complex computations with more than a couple of terms, the `expression()` function provides a good alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS9mRkK9JhiT"
   },
   "source": [
    "### Normalized Difference Vegetation Index\n",
    "\n",
    "As a simple example for using band math is calculating the Normalized Difference Vegetation Index (NDVI) using Landsat imagery, where `add()`, `subtract()`, and `divide()` operators are used:\n",
    "\n",
    "$NDVI = \\frac{NIR-Red}{NIR + Red}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsEDj5EIximr"
   },
   "outputs": [],
   "source": [
    "nir = image.select(\"B5\")\n",
    "red = image.select(\"B4\")\n",
    "\n",
    "ndvi = nir.subtract(red).divide(nir.add(red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzHX6o1eDIsP"
   },
   "outputs": [],
   "source": [
    "def ndvi_exp(image):\n",
    "    ndvi_expr = image.expression('(nir-red)/(nir + red)', {\n",
    "      \"nir\": image.select(\"B5\"),\n",
    "      \"red\": image.select(\"B4\")\n",
    "      })\n",
    "    return ndvi_exp  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLMbNe7zKzKi"
   },
   "outputs": [],
   "source": [
    "# Display original and NDVI images.\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original')\n",
    "Map.addLayer(ndvi, {\"min\":0,\"max\":1}, 'NDVI');\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8l20_5RKYSw"
   },
   "source": [
    "For the complete list of mathematical operators handling basic arithmetic, trigonometry, exponentiation, rounding, casting, bitwise operations and more, see the [API documentation](https://developers.google.com/earth-engine/apidocs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfX-EkNEygua"
   },
   "source": [
    "### Expression example\n",
    "\n",
    "To implement more complex mathematical expressions, consider using `image.expression()`, which parses a text representation of a math operation. The following example uses `expression()` to compute the [Enhanced Vegetation Index (EVI)](https://en.wikipedia.org/wiki/Enhanced_vegetation_index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIbIUfqsyqcs"
   },
   "outputs": [],
   "source": [
    "evi = image.expression(\n",
    "    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "        'NIR': image.select('B5'),\n",
    "        'RED': image.select('B4'),\n",
    "        'BLUE': image.select('B2')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpuFW2lIMG39"
   },
   "outputs": [],
   "source": [
    "# Display original and NDVI images.\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original')\n",
    "Map.addLayer(ndvi, {\"min\":0,\"max\":1}, 'NDVI')\n",
    "Map.addLayer(evi, {\"min\":0,\"max\":2}, 'EVI')\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_UROKCfJKCA"
   },
   "source": [
    "The first argument to `expression()` is the textual representation of the math operation, the second argument is a dictionary where the keys are variable names used in the expression and the values are the image bands to which the variables should be mapped. Bands in the image may be referred to as `b(\"band name\")` or `b(index)`, for example `b(0)`, instead of providing the dictionary. Bands can be defined from images other than the input when using the band map dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7Nfz4EEcLS3"
   },
   "source": [
    "## Zonal statistics\n",
    "\n",
    "To get statistics of pixel values in a region of an ee.Image, use `image.reduceRegion()`. This reduces all the pixels in the region(s) to a statistic or other compact representation of the pixel data in the region (e.g. histogram). The region is represented as a Geometry, which might be a polygon, containing many pixels, or it might be a single point, in which case there will only be one pixel in the region.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "An2O4wh2cQQC"
   },
   "outputs": [],
   "source": [
    "# create a combined reducer that will calculate mean and standard deviation \n",
    "my_reducer = ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True)\n",
    "\n",
    "# calculate mean and stdDev over entire image\n",
    "image_stats = image.reduceRegion(\n",
    "    reducer = my_reducer,\n",
    "    geometry = image.geometry(),\n",
    "    scale = 120,\n",
    "    maxPixels = 1e10,\n",
    "    bestEffort = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77vMs4_-d5an"
   },
   "source": [
    "Note here that the reducers are combined as it is more efficient to combine reducers if you need multiple statistics (e.g. mean and standard deviation) from a single input (e.g. an image region). ([Combining reducers best practice](https://developers.google.com/earth-engine/guides/best_practices#combine-reducers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9L7txGuecqZs"
   },
   "outputs": [],
   "source": [
    "# print the statistics\n",
    "image_stats.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qEM54KncmoD"
   },
   "outputs": [],
   "source": [
    "# convert the dictionary to an image\n",
    "# band names will be the keys\n",
    "# bands will be constant values\n",
    "statistics_image = image_stats.toImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZu73qzadApx"
   },
   "outputs": [],
   "source": [
    "# extract out the mean and standard deviation bands\n",
    "# to two seperate images\n",
    "mean_image = statistics_image.select(\"B.*_mean\")\n",
    "stdDev_image = statistics_image.select(\"B.*_stdDev\")\n",
    "\n",
    "# calculate z-score\n",
    "zscore = image.select(\"B.*\").subtract(mean_image).divide(stdDev_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CDwFIMdcpzc"
   },
   "outputs": [],
   "source": [
    "# Display original and scaled images.\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original')\n",
    "Map.addLayer(zscore, {\"bands\": [\"B7\",\"B5\",\"B3\"],\"min\":-2.5,\"max\":2.5}, 'Std. Deviation Stretch')\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1cTIKnRxdiO",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Neighborhood operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgv6TSLx5kdH"
   },
   "source": [
    "### Linear filters\n",
    "\n",
    "In the present context, linear filtering (or [convolution](http://www.dspguide.com/ch24/1.htm) refers to a linear combination of pixel values in a neighborhood.  The neighborhood is specified by a [kernel](https://en.wikipedia.org/wiki/Kernel_(image_processing)), where the weights of the kernel determine the coefficients in the linear combination.  (For this lab, the terms kernel and filter are interchangeable.)  Filtering an image can be useful for extracting image information at different spatial frequencies.  For this reason, smoothing filters are called low-pass filters (they let low-frequency data pass through) and edge detection filters are called high-pass filters.  To implement filtering in Earth Engine use `image.convolve()` with an `ee.Kernel` for the argument.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "femcb-VC6T77"
   },
   "source": [
    "#### Smoothing. \n",
    "\n",
    "Smoothing means to convolve an image with a smoothing kernel.  A simple smoothing filter is a square kernel with uniform weights that sum to one.  Convolving with this kernel sets each pixel to the mean of its neighborhood.  Print a square kernel with uniform weights (this is sometimes called a \"pillbox\" or \"boxcar\" filter):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEvs1Hl85jtV"
   },
   "outputs": [],
   "source": [
    "# Define a uniform kernel and print to see its weights.\n",
    "uniform_kernel = ee.Kernel.square(2)\n",
    "\n",
    "pprint(uniform_kernel.getInfo());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1PM29Vgxg5-"
   },
   "outputs": [],
   "source": [
    "# Filter the image by convolving with the smoothing filter.\n",
    "smoothed = image.convolve(uniform_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2A8R9CRt7B6f"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(smoothed, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Smoothed');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFrDqmca7JJs"
   },
   "source": [
    "To make the image even more smooth, try increasing the size of the neighborhood by increasing the pixel radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8BuCNEj7KJx"
   },
   "source": [
    "A Gaussian kernel can also be used for smoothing.  Think of filtering with a Gaussian kernel as computing the weighted average in each pixel's neighborhood.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxlXh2Qi7WbJ"
   },
   "outputs": [],
   "source": [
    "# define a gaussian kernel\n",
    "gaussian_kernel = ee.Kernel.gaussian(2)\n",
    "\n",
    "pprint(gaussian_kernel.getInfo(),width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFzlLxzz7eo5"
   },
   "outputs": [],
   "source": [
    "# apply the gaussian kernel on the image\n",
    "gaussian = image.convolve(gaussian_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnOvtTe37wcA"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(gaussian, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Gaussian');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3xCegnW75vw"
   },
   "source": [
    "#### Edge Detection\n",
    "\n",
    "Convolving with an edge-detection kernel is used to find rapid changes in DNs that usually signify edges of objects represented in the image data. \n",
    "\n",
    "A classic edge detection kernel is the [Sobel](https://en.wikipedia.org/wiki/Sobel_operator) kernel.  Investigate the kernel weights and the image that results from convolving with the Sobel kernel:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oE-CwDsD8TgT"
   },
   "outputs": [],
   "source": [
    "# Define a Sobel filter.\n",
    "x_sobel_kernel = ee.Kernel.sobel()\n",
    "y_sobel_kernel = x_sobel_kernel.rotate(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ogNWtFI8YR7"
   },
   "outputs": [],
   "source": [
    "# Print the kernel to see its weights.\n",
    "pprint(x_sobel_kernel.getInfo())\n",
    "pprint(y_sobel_kernel.getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2wS2jVs8ihT"
   },
   "outputs": [],
   "source": [
    "x_edges = (\n",
    "    image\n",
    "    .convolve(x_sobel_kernel)\n",
    ")\n",
    "\n",
    "y_edges = (\n",
    "    image\n",
    "    .convolve(y_sobel_kernel)\n",
    ")\n",
    "\n",
    "edges = (\n",
    "    x_edges.pow(2).add(y_edges.pow(2)).sqrt()\n",
    "    .reproject(proj, None, proj.nominalScale()) # force processing at native projection for visualization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbq6z04m9i5L"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(edges, {\"min\": 0, \"max\": 2000,}, 'Edges');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOONc9tP8Jjo"
   },
   "source": [
    "(Ignore the `reproject()` call for now.  It is explained in section 7.)\n",
    "\n",
    "Other edge detection kernels include the [Laplacian](https://en.wikipedia.org/wiki/Discrete_Laplace_operator), [Prewitt](https://en.wikipedia.org/wiki/Prewitt_operator) and [Roberts](https://en.wikipedia.org/wiki/Roberts_cross) kernels.  [Learn more about additional edge detection methods in Earth Engine](https://developers.google.com/earth-engine/image_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxJQ3tWlAjpj"
   },
   "source": [
    "#### Sharpening.  \n",
    "\n",
    "Image sharpening, or edge enhancement, is related to the idea of the image second derivative.  Specifically, mimic the perception of Mach bands in human optical response by adding the image to its second derivative.\n",
    "\n",
    "One implementation of this idea is to convolve an image with a Laplacian-of-a-Gaussian or [Difference-of-Gaussians](https://en.wikipedia.org/wiki/Difference_of_Gaussians) filter (see [Schowengerdt 2007](http://www.sciencedirect.com/science/book/9780123694072) for details), then add that to the input image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwUsya7ZA9z1"
   },
   "outputs": [],
   "source": [
    "# Define a \"fat\" Gaussian kernel.\n",
    "fat = ee.Kernel.gaussian(\n",
    "  radius= 3,\n",
    "  sigma= 3,\n",
    "  magnitude= -1,\n",
    "  units= 'meters'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cusxwfT4BC9K"
   },
   "outputs": [],
   "source": [
    "# Define a \"skinny\" Gaussian kernel.\n",
    "skinny = ee.Kernel.gaussian(\n",
    "  radius= 3,\n",
    "  sigma= 0.5,\n",
    "  units= 'meters'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPN0CjQ4BInD"
   },
   "outputs": [],
   "source": [
    "# Compute a difference-of-Gaussians (DOG) kernel.\n",
    "dog = fat.add(skinny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqkUReSJBM4Z"
   },
   "outputs": [],
   "source": [
    "# Add the DoG filtered image to the original image.\n",
    "sharpened = (\n",
    "    image.add(image.convolve(dog))\n",
    "    .reproject(proj, None, proj.nominalScale()) # force processing at native projection for visualization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxF_adC3BSIR"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "# Display gamma stretches of the input image.\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(sharpened, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Sharpened');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XatueHLFBiZY"
   },
   "source": [
    "Related concepts include [*spectral inversion*](http://www.dspguide.com/ch14/5.htm) from digital signal processing and unsharp masking ([Burger and Burge 2008](http://imagingbook.com/)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7GKZo6nCYi-"
   },
   "source": [
    "### Non-linear filtering\n",
    "\n",
    "The previous convolution examples can all be implemented as linear combinations of pixel values in a neighborhood (edge detection sometimes needs a couple extra steps, but nevermind that).  Non-linear functions applied to a neighborhood are also useful.  Implement these functions in Earth Engine with the `reduceNeighborhood()` method on images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lI9Zr51WI4T"
   },
   "source": [
    "#### Median\n",
    "\n",
    "A median filter can be useful for denoising images.  Specifically, suppose that random pixels in your image are saturated by anomalously high or low values that result from some noise process.  Filtering the image with a mean filter (as in the \"Smoothing\" section) would result in pixel values getting polluted by noisy data.  To avoid that, smooth the image with a median filter (reusing the 5x5 uniform kernel from above):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0BCfI3iCinQ"
   },
   "outputs": [],
   "source": [
    "median = image.reduceNeighborhood(\n",
    "  reducer= ee.Reducer.median(), \n",
    "  kernel= uniform_kernel\n",
    ").rename(image.bandNames())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sCZKNFLWh1p"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "# Display gamma stretches of the input image.\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(median, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Median');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-oywD0nW45L"
   },
   "source": [
    "#### Mode\n",
    "\n",
    "For categorical maps, methods such as median and mean make little sense for aggregating nominal data.  In these cases, use neighborhood mode to get the most frequently occurring value.\n",
    "\n",
    "For demonstration purposes, we will load in another dataset that represents land cover and apply the mode filter on:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV9WxRM-W6la"
   },
   "outputs": [],
   "source": [
    "# load in a clssified land cover image from the NLCD collection\n",
    "landcover = (\n",
    "    ee.ImageCollection(\"USGS/NLCD_RELEASES/2016_REL\")\n",
    "    .first()\n",
    "    .select(['landcover'])  # Select the classification band of interest.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enUSt0KwYQLR"
   },
   "outputs": [],
   "source": [
    "# Smooth with a mode filter.\n",
    "mode_filtered = landcover.focal_mode(radius=2);\n",
    "\n",
    "# this is the equivalent calling reduceNeigborhood with \n",
    "# a mode reducer and 5x5 uniform kernel\n",
    "# image.reduceNeighborhood(\n",
    "#     reducer = ee.Reducer.mode(),\n",
    "#     ...\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Enh2VU-9azeT"
   },
   "outputs": [],
   "source": [
    "# copy properties from the original landcover image so it displays correctly\n",
    "mode_filtered = ee.Image(mode_filtered.copyProperties(landcover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZJ_lsX7Y0hz"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 7)\n",
    "\n",
    "Map.addLayer(landcover, {}, 'Original Landcover');\n",
    "Map.addLayer(mode_filtered, {}, 'Landcover mode');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM6xiAgVOJYa"
   },
   "source": [
    "## Image Segementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKnQPtFmytvn"
   },
   "outputs": [],
   "source": [
    "# alternate approach for calculating a normalized difference\n",
    "mndwi = image.normalizedDifference([\"B3\",\"B6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hixdyw_0OUtF"
   },
   "outputs": [],
   "source": [
    "threshold = 0.1 # define a threshold to segment the image\n",
    "water = mndwi.gt(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOP8BRvOOMhK"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(mndwi, {\"min\": -0.5, \"max\": 1,}, 'MNDWI');\n",
    "Map.addLayer(water, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Water');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNBtu_bAxwKk"
   },
   "source": [
    "## Morphological operations\n",
    "\n",
    "The idea of morphology is tied to the concept of objects in images.  For example, suppose the patches of 1's in the water image from the previous section represent patches of water."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uM_GLk7Q-Td"
   },
   "source": [
    "###Dilation (max). \n",
    "\n",
    "If the patches underestimate the actual distribution of water, or contain \"holes\", a max filter can be applied to [dilate](https://en.wikipedia.org/wiki/Dilation_(morphology)) the areas of water:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izEpFx95x0JJ"
   },
   "outputs": [],
   "source": [
    "# Dilate by takaing the max in each 5x5 neighborhood.\n",
    "max = water.reduceNeighborhood(\n",
    "  reducer= ee.Reducer.max(), \n",
    "  kernel= uniform_kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNug6mWbRhHR"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(water, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Water');\n",
    "Map.addLayer(max, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Dilation');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUnl1HoyRzJR"
   },
   "source": [
    "### Erosion (min).  \n",
    "\n",
    "The opposite of dilation is [erosion](https://en.wikipedia.org/wiki/Erosion_(morphology), for decreasing the size of the patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoi6vpFZR4K0"
   },
   "outputs": [],
   "source": [
    "# Erode by takaing the min in each 5x5 neighborhood\n",
    "min = water.reduceNeighborhood(\n",
    "  reducer= ee.Reducer.min(), \n",
    "  kernel= uniform_kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIl9eSjVR_1_"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(water, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Water');\n",
    "Map.addLayer(min, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Erosion');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YuG-_avSRJc"
   },
   "source": [
    "### Opening\n",
    "\n",
    "To \"open\" possible \"holes\" in the patches, perform an erosion followed by a dilation.  This process is called [opening](https://en.wikipedia.org/wiki/Opening_(morphology)).  Try that by performing a dilation of the eroded image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BR5gl5lzSK5v"
   },
   "outputs": [],
   "source": [
    "# Perform an opening by dilating the eroded image.\n",
    "opened = min.reduceNeighborhood(\n",
    "  reducer= ee.Reducer.max(), \n",
    "  kernel= uniform_kernel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJcpKlO3Sd9c"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(water, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Water');\n",
    "Map.addLayer(opened, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Opened');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RllF4cASnB9"
   },
   "source": [
    "### Closing\n",
    "\n",
    "The opposite of opening is [closing](https://en.wikipedia.org/wiki/Closing_(morphology)), or dilation followed by a erosion.  Use this to \"close\" possible \"holes\" in the input patches:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3EdD6S5St-x"
   },
   "outputs": [],
   "source": [
    "# Perform a closing by eroding the dilated image.\n",
    "closed = max.reduceNeighborhood(\n",
    "  reducer= ee.Reducer.min(), \n",
    "  kernel= uniform_kernel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtU-GbvSS2HO"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(water, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Water');\n",
    "Map.addLayer(closed, {\"min\": 0, \"max\": 1, \"palette\":\"black,lightblue\"}, 'Closed');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71T9C9wCS_7Q"
   },
   "source": [
    "Examine the difference between each morphological operation and the water input.  Tune these morphological operators by adjusting the size and shape of the kernel (also called a [*structuring element*](https://en.wikipedia.org/wiki/Structuring_element) in this context, because of its effect on the shape of the result), or applying the operations repetively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAPfCb_7yALQ"
   },
   "source": [
    "## Compositing\n",
    "\n",
    "Compositing is the process of taking multiple images and making a single representative image using some statistical reduction. There are multiple ways to achieve composites and an active research area. Really the composite apporach you use depends on the data and application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XonDCgVzXMP"
   },
   "source": [
    "### Mean vs Median Composite\n",
    "\n",
    "Mean/Medain compositing is very common and this illustrates the general workflow to create such a composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K-avD1dyFqV"
   },
   "outputs": [],
   "source": [
    "# load in an image collection and filter by space and time\n",
    "l8 = (\n",
    "    ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "    .filterDate('2021-01-01', '2022-01-01')\n",
    "    .filterBounds(ee.Geometry.Rectangle([-124.736342, 24.521208, -66.945392, 49.382808]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-jAXSiuzmd6"
   },
   "outputs": [],
   "source": [
    "# first step is to usually mask out poor quality observations\n",
    "# this function takes a landsat image and reads the QA band \n",
    "# to determine which pixels are good or bad then\n",
    "# masks (sets to nodata) poor quality pixels\n",
    "def qa(img):\n",
    "    # Bits 3, 4 and 5 are cloud shadow, snow and cloud, respectively.\n",
    "    cloudshadow_bit_mask = 1 << 3\n",
    "    snow_bit_mask = 1 << 4\n",
    "    clouds_bit_mask = 1 << 5\n",
    "    \n",
    "\n",
    "    # Get the pixel QA band.\n",
    "    qa = img.select('pixel_qa')\n",
    "\n",
    "    # All flags should be set to zero, indicating clear conditions.\n",
    "    cloudshadow_mask = qa.bitwiseAnd(cloudshadow_bit_mask).eq(0)\n",
    "    snow_mask = qa.bitwiseAnd(snow_bit_mask).eq(0)\n",
    "    cloud_mask = qa.bitwiseAnd(clouds_bit_mask).eq(0)\n",
    "\n",
    "    # combine the masks to identify where it is clear in all cases\n",
    "    mask = cloudshadow_mask.And(snow_mask).And(cloud_mask)\n",
    "\n",
    "    # Return the masked image, scaled to reflectance, without the QA bands.\n",
    "    return (\n",
    "        img.updateMask(mask)\n",
    "        .select(\"B[0-9]*\")\n",
    "        .copyProperties(img, [\"system:time_start\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8YD4gfl1NYK"
   },
   "outputs": [],
   "source": [
    "# apply the QA function to mask poor quality observations\n",
    "l8_qa = l8.map(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRTSgiXo1WYp"
   },
   "outputs": [],
   "source": [
    "# apply mean reductions\n",
    "l8_mean_comp = l8_qa.reduce(ee.Reducer.mean())\n",
    "\n",
    "# apply median reduction\n",
    "l8_median_comp = l8_qa.median()\n",
    "\n",
    "# this is the equivalent calling .reduce() with \n",
    "# a median reducer\n",
    "# image.reduce(ee.Reducer.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lHVzx2P2je1"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(l8_median_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Median Composite');\n",
    "Map.addLayer(l8_mean_comp, {\"bands\": [\"B7_mean\",\"B5_mean\",\"B3_mean\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Mean Composite');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpjqGz0gzh0q"
   },
   "source": [
    "### Quality band composite\n",
    "\n",
    "Sometimes it is useful to create a composite based on a specific variable that is of interest. For example, if we are interested in creating an image of peak vegetation per-pixel we can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2qOsj7MyriV"
   },
   "outputs": [],
   "source": [
    "# create a function to calculate NDVI and\n",
    "# add the ndvi band to the original image\n",
    "def ndvi(img):\n",
    "    ndvi = img.normalizedDifference([\"B5\",\"B4\"]).rename(\"NDVI\")\n",
    "    return img.addBands(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1Mjac025gVx"
   },
   "outputs": [],
   "source": [
    "# apply the ndvi function to each image\n",
    "l8_ndvi = l8_qa.map(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVu3GTrk5pG2"
   },
   "outputs": [],
   "source": [
    "# create a composite using the maximum ndvi value\n",
    "l8_ndvi_comp = l8_ndvi.qualityMosaic(\"NDVI\")\n",
    "l8_max_comp = l8_ndvi.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqaRV3tN5vnw"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(l8_median_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Median Composite');\n",
    "Map.addLayer(l8_mean_comp, {\"bands\": [\"B7_mean\",\"B5_mean\",\"B3_mean\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Mean Composite');\n",
    "Map.addLayer(l8_ndvi_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'NDVI Composite');\n",
    "Map.addLayer(l8_max_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Max Composite');\n",
    "\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS1peMgCzbHw"
   },
   "source": [
    "### Time based composite\n",
    "\n",
    "While we can mosaic based on all of the imagery and a statistic, we can also composite based on data closest to a specific date of interest. To do this, we can create a band based on time and use `.quality_mosaic()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUJHcu6p6FPu"
   },
   "outputs": [],
   "source": [
    "# define a reference date that we want to composite on\n",
    "REFERENCE_DATE = \"2018-11-15\"\n",
    "\n",
    "# create a function that calculates the difference from an\n",
    "# acquisition from the reference date\n",
    "# adds the time difference as a band to the image\n",
    "def add_time(img):\n",
    "    t = img.date()\n",
    "    t_diff = t.difference(ee.Date(REFERENCE_DATE), \"day\").abs().multiply(-1)\n",
    "    time = ee.Image(t_diff).float().rename(\"time\")\n",
    "    time = time.updateMask(img.select([0]).mask())\n",
    "    return img.addBands(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaW8P2B77qrl"
   },
   "outputs": [],
   "source": [
    "# apply the function to calculate a time band\n",
    "l8_time = l8_qa.map(add_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHoHyiy17zXe"
   },
   "outputs": [],
   "source": [
    "# create a composite based on the maximum time band\n",
    "l8_time_comp = l8_time.qualityMosaic(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBMz9N2t75ca"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(l8_median_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Median Composite');\n",
    "Map.addLayer(l8_mean_comp, {\"bands\": [\"B7_mean\",\"B5_mean\",\"B3_mean\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Mean Composite');\n",
    "Map.addLayer(l8_time_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Time Composite');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R28uLWbRzC_n"
   },
   "source": [
    "These are examples of compositing techniques. Again, how you composite your imagery will be based on your application. A well-known example of a peer-reviewed compositing approach is the Best Avaiable Pixel (BAP) composite ([White et al., 2014](https://www.tandfonline.com/doi/full/10.1080/07038992.2014.945827))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HA8hFogLdbL"
   },
   "source": [
    "It is worth noting that composite images created by reducing an image collection are able to produce pixels in any requested projection and therefore have no fixed output projection. Instead, composites have the [default projection](https://developers.google.com/earth-engine/guides/projections#the-default-projection) of WGS-84 with 1-degree resolution pixels. Composites with the default projection will be computed in whatever output projection is requested. A request occurs by displaying the composite, or by explicitly specifying a projection/scale as in an aggregation such as `reduceRegion()` or `ee.batch.Export`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dt1e35M9x-Pk"
   },
   "source": [
    "## Resampling and Reprojection\n",
    "\n",
    "Earth Engine makes every effort to handle projection and scale so that you don't have to.  However, there are occasions where an understanding of projections is important to get the output you need.  As an example, it's time to demystify the `reproject()` calls in the previous examples.  Earth Engine requests inputs to your computations in the projection and scale of the output.  The map created using `geemap` has a [Maps Mercator projection](http://epsg.io/3857).  The scale is determined from the map's zoom level.  When you add something to this map, Earth Engine secretly reprojects the input data to Mercator, resampling (with nearest neighbor) to screen resolution pixels based on the map's zoom level, then does all the computations with the reprojected, resampled imagery.  In the previous examples, the `reproject()` calls force the computations to be done at the resolution of the input pixels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxGNHnCJTzNB"
   },
   "source": [
    "To demonstrate the resampling done by Earth Engine, we are going to re-run the edge detection and display with and without the reprojection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeiQLAetx_NQ"
   },
   "outputs": [],
   "source": [
    "# calculate edges without reprojection\n",
    "edges_variable = (\n",
    "    x_edges.pow(2).add(y_edges.pow(2)).sqrt()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDZpUkbBUKOM"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 21)\n",
    "\n",
    "# Display gamma stretches of the input image.\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(edges_variable, {\"min\": 0, \"max\": 2000,}, 'Edges with little screen pixels');\n",
    "Map.addLayer(edges, {\"min\": 0, \"max\": 2000,}, 'Edges at native resolution');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sagthgg7Uxvz"
   },
   "source": [
    "What's happening here is that the projection specified in `reproject()` (like we used earlier) propagates backwards to the input, forcing all the computations to be performed in that projection.  If you don't specify, the computations are performed in the projection and scale of the map (Mercator) at screen resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF6Tbx2rU-h4"
   },
   "source": [
    "You can control how Earth Engine resamples the input with `resample()`.  By default, all resampling is done with nearest neighbor.  To change that, call `resample()` on the inputs.  Compare the input image, resampled to screen resolution with a bilinear and bicubic resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLWDRzyKVFZf"
   },
   "outputs": [],
   "source": [
    "# Resample the image with bilinear instead of nearest neighbor.\n",
    "bilinear_resampled = image.resample('bilinear');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATpbQhSMVJq3"
   },
   "outputs": [],
   "source": [
    "# Resample the image with bicubic instead of nearest neighbor.\n",
    "bicubic_resampled = image.resample('bicubic');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxGvRA0VVQG3"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 16)\n",
    "\n",
    "# Display gamma stretches of the input image.\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original (Nearest neighbor)');\n",
    "Map.addLayer(bilinear_resampled, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Bilinear resampled');\n",
    "Map.addLayer(bicubic_resampled, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Bicubic resampled');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09YAZo1UVQOb"
   },
   "source": [
    "Try zooming in and out, comparing to the input image resampled with nearest neighbor (i.e. without `resample()` called on it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1nD64GcTlf-"
   },
   "source": [
    "**_You should rarely, if ever, have to use `reproject()` and `resample()`._** Do not use `reproject()` or `resample()` unless absolutely necessary.  They are only used here for demonstration purposes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 3 - Digital imagery and image processing.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
