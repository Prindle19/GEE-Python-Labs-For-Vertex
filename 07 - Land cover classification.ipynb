{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJvAqpdJxhx2"
   },
   "source": [
    "# Lab 7: Land cover classification\n",
    "\n",
    "**Purpose:** The purpose of this lab is to explore different approaches to land cover classification using Earth Engine. Students will explore sampling methods to gather training datasets for land cover classification methods as well as applying unsupervised and supervised classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wp_ymuPH39yl"
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "from geemap import colormaps as cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1JLpElR3_cC"
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duo-LbTT4BkA"
   },
   "source": [
    "## Background\n",
    "\n",
    "Land cover classification has deep roots in the remote sensing community. One of the first applications of satellite image was to create land cover maps. \n",
    "\n",
    "No matter what you would like to call the approaches the workflow is the same:\n",
    "1. Identify classification problem (what are you classifying)\n",
    "2. Make sure you have an image (or images) that will be used for collecting data\n",
    "3. Sample data from image(s) as input into model\n",
    "4. Train/fit model\n",
    "5. Apply model to image(s)\n",
    "6. Check results (verification/validation)\n",
    "7. Refine and iterate\n",
    "\n",
    "As a prompt for the exercise within this notebook, imagine that you are a consultant that is setting up a hydrology model in a region that does not have an existing land cover dataset. You need to use remote sensing data to create a land cover dataset for parameterization of your model. The resulting land cover class won't need to be to complex (we are using CN method) so we will try to replicate the NLCD dataset for another country. This way we can use the parameterization from established NLCD classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3et2vEpNl5u"
   },
   "source": [
    "## Image Compositing\n",
    "\n",
    "Following along our steps for classification, we know what we will be using our land cover map for and the target classes we will now need an image to run the classification. We will use Landsat to create a composite for one year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKtZhpLWSoMw"
   },
   "outputs": [],
   "source": [
    "l8_collection = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5bM2acNStNm"
   },
   "outputs": [],
   "source": [
    "# this loads in a global vector file of countries\n",
    "# filter by country of interest\n",
    "region = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\").filter(\n",
    "    ee.Filter.eq(\"country_na\",\"United States\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jw-2PQTDTdVH"
   },
   "outputs": [],
   "source": [
    "# specify time to filter data\n",
    "# using an NLCD release year\n",
    "start_time = \"2019-05-01\"\n",
    "end_time = \"2019-10-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaFpHsaNTXkc"
   },
   "outputs": [],
   "source": [
    "l8_filtered = l8_collection.filterBounds(region).filterDate(start_time,end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Okf35G8q4A_i"
   },
   "outputs": [],
   "source": [
    "# QA mask function\n",
    "def qa_mask(image):\n",
    "    #Bits 3, 4, and 5 are cloud shadow, snow, and cloud, respectively.\n",
    "    cloudShadowBitMask = (1 << 3);\n",
    "    cloudsBitMask = (1 << 5);\n",
    "    snowBitMask = (1 << 4);\n",
    "\n",
    "    #Get the pixel QA band.\n",
    "    qa = image.select('pixel_qa');\n",
    "\n",
    "    # apply the bit shift and get binary image of different QA flags\n",
    "    cloud_shadow_qa = qa.bitwiseAnd(cloudShadowBitMask).eq(0)\n",
    "    snow_qa = qa.bitwiseAnd(snowBitMask).eq(0)\n",
    "    cloud_qa = qa.bitwiseAnd(cloudsBitMask).eq(0)\n",
    "\n",
    "    # combine qa mask layers to one final mask\n",
    "    mask = cloud_shadow_qa.And(snow_qa).And(cloud_qa)\n",
    "\n",
    "    # apply mask and return orignal image\n",
    "    return image.updateMask(mask);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbjEN7w6Uh5t"
   },
   "outputs": [],
   "source": [
    "# apply qa and composite (using median reducer at the moment)\n",
    "l8_composite = l8_filtered.map(qa_mask).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rBj1ZwRUTCF"
   },
   "source": [
    "Check to make sure our composite is doing what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CF6RqSOSntF"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region, 5); \n",
    "\n",
    "Map.addLayer(region,{},\"United States\")\n",
    "Map.addLayer(l8_composite, {\"bands\":\"B7,B5,B3\", \"min\": 50, \"max\": 5500,\"gamma\":1.5}, 'L8 Composite');\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnDoVuDIXeiU"
   },
   "source": [
    "## Sample data\n",
    "\n",
    "Now that we have an image we need to sample data to use within a model. There are a couple ways to do this with Earth Engine but we will focus on the most straight forward approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XL9R9bL2YkZA"
   },
   "outputs": [],
   "source": [
    "# load in the NLCD data from 2019\n",
    "nlcd = (\n",
    "    ee.ImageCollection(\"USGS/NLCD_RELEASES/2019_REL/NLCD\")\n",
    "    .first()\n",
    "    .select(\"landcover\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s01XkeJXZGpU"
   },
   "outputs": [],
   "source": [
    "# combine the images together to sample from\n",
    "sample_img = l8_composite.select(\"B[2-7]\").addBands(nlcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUqggyUhgIXQ"
   },
   "outputs": [],
   "source": [
    "# define which are feature inputs vs labels/targets\n",
    "# these are used later on in the notebook\n",
    "feature_names = l8_composite.select(\"B[2-7]\").bandNames()\n",
    "label_name = \"landcover\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uONPkrXQZM9Y"
   },
   "source": [
    "### Simple Random Sampling\n",
    "\n",
    "The easiest approach to sample randomly throughout the domain. Doing this has pros and cons we will explore these later on. Here is how you sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AceTdFn8ZEp5"
   },
   "outputs": [],
   "source": [
    "random_samples = sample_img.sample(\n",
    "    region = region.geometry().bounds(),\n",
    "    numPixels = 2500, # number of samples to collect, in this case 2500 \n",
    "    scale = 30, # important to be explicit about scale here, we want the data at native resolution\n",
    "    seed = 7,\n",
    "    tileScale = 4,\n",
    "    geometries = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrUVxDePanuX"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region, 5); \n",
    "\n",
    "Map.addLayer(region,{},\"United States\")\n",
    "Map.addLayer(l8_composite, {\"bands\":\"B7,B5,B3\", \"min\": 50, \"max\": 5500,\"gamma\":1.5}, 'L8 Composite');\n",
    "Map.addLayer(nlcd, {}, 'NLCD');\n",
    "Map.addLayer(random_samples, {}, 'Random Samples');\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv9oGIXUavfI"
   },
   "source": [
    "### Stratified Random Sampling\n",
    "\n",
    "Another more robust approach to sample is the randomly sample within classes. This ensures that classes with smaller areas are sampled and not missed. Again, this has pros and cons but this is generally the approach used. Here is how you apply the stratified sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ou6CFWnMcfFh"
   },
   "outputs": [],
   "source": [
    "# stratified sampling require class values to sample and how much\n",
    "# here we define the values for each class\n",
    "# and create a list of number of samples per class\n",
    "nlcd_classes = ee.List([11,12,21,22,23,24,31,41,42,43,51,52,71,72,73,74,81,82,90,95])\n",
    "\n",
    "n_classes = nlcd_classes.length()\n",
    "n_points = 1000\n",
    "perclass_points = ee.Number(n_points).divide(n_classes).round()\n",
    "\n",
    "class_num = ee.List.repeat(perclass_points, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH8InrzjX0zP"
   },
   "outputs": [],
   "source": [
    "stratified_samples = sample_img.stratifiedSample(\n",
    "    region = region.geometry().bounds(),\n",
    "    numPoints = 10,  \n",
    "    classBand = label_name, \n",
    "    classValues = nlcd_classes, \n",
    "    classPoints = class_num,\n",
    "    scale = 30, # important to be explicit about scale here, we want the data at native resolution\n",
    "    seed = 7,\n",
    "    tileScale = 4,\n",
    "    # geometries = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaoVa9QiYI1-"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region, 5); \n",
    "\n",
    "Map.addLayer(region,{},\"United States\")\n",
    "Map.addLayer(l8_composite, {\"bands\":\"B7,B5,B3\", \"min\": 50, \"max\": 5500,\"gamma\":1.5}, 'L8 Composite');\n",
    "Map.addLayer(nlcd, {}, 'NLCD');\n",
    "Map.addLayer(stratified_samples, {}, 'Stratified Random Samples');\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YXbBGbJlD7g"
   },
   "source": [
    "You may get a computation time out error, this unfortunately happens because the process takes a while to run and EE's internal scheduler does not allow interactive processing to run too long to share resources. One way that is strongly advised is to export intermidiate results. The following code will export the stratified samples to an asset that we can load in later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSgfPZmDjhKS"
   },
   "outputs": [],
   "source": [
    "ee_asset_id = \"kmarkert\" # change to your id to export to your assets\n",
    "\n",
    "task = ee.batch.Export.table.toAsset(\n",
    "    collection = stratified_samples,\n",
    "    description = \"NLCD_sample_export\",\n",
    "    assetId = f\"users/{ee_asset_id}/CE594_NLCD_stratified_samples\"\n",
    ")\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sYCBd9wIhfI"
   },
   "outputs": [],
   "source": [
    "geemap.ee_user_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9U1L61ClmYl"
   },
   "source": [
    "It is hard to tell how long exports will run. I have pre-exported these samples so we can continue with our exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ib8OzQ8NlkJ5"
   },
   "outputs": [],
   "source": [
    "# load in the pre-exported samples\n",
    "stratified_samples = ee.FeatureCollection(\"users/kmarkert/CE594_NLCD_stratified_samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu0Fc0vzRiuC"
   },
   "source": [
    "## Unsupervised Classification\n",
    "\n",
    "Now that we have our samples we can start apply some classification techniques. Before we get into supervised classification (which is what we are set up to do), we are going to try unsupervised classification and see what that gives us.\n",
    "\n",
    "For classification/clustering on EE, there are very straightforward steps:\n",
    "1. define a model and parameters\n",
    "2. train/fit the model\n",
    "3. apply model on imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4WSp6m-RiIS"
   },
   "outputs": [],
   "source": [
    "# first step is to define a model\n",
    "# get a KMeans clusterer object\n",
    "kmeans = (\n",
    "    ee.Clusterer.wekaKMeans(\n",
    "        nClusters=n_classes, # specify same number of classes as NLCD\n",
    "        init=1 # init model with k-means++\n",
    "    )\n",
    "    # apply training all at once to avoid having to return another object\n",
    "    .train(random_samples, inputProperties=feature_names)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3owEppWgZy8"
   },
   "outputs": [],
   "source": [
    "# apply model to image\n",
    "cluster_img = sample_img.cluster(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKI5HWJgggxG"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region, 5); \n",
    "\n",
    "Map.addLayer(region,{},\"United States\")\n",
    "Map.addLayer(l8_composite, {\"bands\":\"B7,B5,B3\", \"min\": 50, \"max\": 5500,\"gamma\":1.5}, 'L8 Composite');\n",
    "Map.addLayer(nlcd, {}, 'NLCD');\n",
    "Map.addLayer(cluster_img.randomVisualizer(), {}, 'Clustered image');\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xXzQaahhUq-"
   },
   "source": [
    "There are other clustering algorithms, like XMeans, available on EE which I encourage you to explore. However, clustering is every good for data exploration and if you have labels a better approach is to use supervised classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPCPyNfMgpuL"
   },
   "source": [
    "## Supervised classification\n",
    "\n",
    "Now to the task at hand...we want to classify our \n",
    "\n",
    "We will use well used and fancy classifier called a random forest ([Breiman 2001](https://link.springer.com/article/10.1023/A:1010933404324)).  A random forest is a collection of random decision trees the predictions of which are used to compute an average (regression) or vote on a label (classification). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkjwWhRGgo-8"
   },
   "outputs": [],
   "source": [
    "# first step is to define a model\n",
    "# get a Random Forest classifier object\n",
    "\n",
    "rf = (\n",
    "    ee.Classifier.smileRandomForest(\n",
    "        numberOfTrees = 20, # specify number of trees to use for classification\n",
    "    )\n",
    "    # again train in one-go to prevent returning another object\n",
    "    .train(\n",
    "        random_samples,\n",
    "        classProperty = label_name, \n",
    "        inputProperties = feature_names\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7r9r5FCJiyc3"
   },
   "outputs": [],
   "source": [
    "# apply the classifier to our composite image\n",
    "classified_img = sample_img.classify(rf).uint8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pv4_6aY0pJLq"
   },
   "outputs": [],
   "source": [
    "lc_vis_values = nlcd.get(\"landcover_class_values\")\n",
    "lc_vis_colors = nlcd.get(\"landcover_class_palette\")\n",
    "\n",
    "# set image metadata to automatically visualize values and palette\n",
    "classified_img = classified_img.set({\n",
    "    \"classification_class_values\":nlcd_classes,\n",
    "    \"classification_class_palette\":lc_vis_colors,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8x2VeG_Cjc94"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region, 5); \n",
    "\n",
    "Map.addLayer(region,{},\"United States\")\n",
    "Map.addLayer(l8_composite, {\"bands\":\"B7,B5,B3\", \"min\": 50, \"max\": 5500,\"gamma\":1.5}, 'L8 Composite');\n",
    "Map.addLayer(nlcd, {}, 'NLCD');\n",
    "Map.addLayer(classified_img, {}, 'Classified image');\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBFlhKWJkjzq"
   },
   "source": [
    "### Accuracy assessment\n",
    "\n",
    "It is generally good practice to split the dataset into training and testing so we have an idea of how well our model does at estimating our labels. We did not do this earlier to avoid confusion, however, we will do this now and get an idea of accuracy using EE. In the classification context, accuracy measurements are often derived from a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "First step is to randomly split the data, we can easily do this by reusing the classification training set, add a column of random numbers used to partition the known data where about 70% of the data will be used for training and 30% for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzRdhxU7kjV-"
   },
   "outputs": [],
   "source": [
    "# set a random column to table\n",
    "stratified_samples_random = random_samples.randomColumn()\n",
    "\n",
    "# split into training and testing\n",
    "train_samples = stratified_samples_random.filter(ee.Filter.lte(\"random\",0.7))\n",
    "test_samples = stratified_samples_random.filter(ee.Filter.gt(\"random\",0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mav36MzqnGQf"
   },
   "source": [
    "Now train a model only using the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3qAeZEfm55a"
   },
   "outputs": [],
   "source": [
    "# get a Random Forest classifier object\n",
    "rf = (\n",
    "    ee.Classifier.smileRandomForest(\n",
    "        numberOfTrees = 20, # specify number of trees to use for classification\n",
    "    )\n",
    "    # again train in one-go to prevent returning another object\n",
    "    .train(\n",
    "        train_samples, # note only training on train samples\n",
    "        classProperty = label_name, \n",
    "        inputProperties = feature_names\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80jaBVnJnJtj"
   },
   "source": [
    "Apply the model to the test dataset. Note: here we are applying the classification model to a table and the classifier automatically adds a property called 'classification'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0mApGicnDtc"
   },
   "outputs": [],
   "source": [
    "# apply the classifier just like we would with an image\n",
    "# this returns the original table but now with a classified column\n",
    "pred_samples = test_samples.classify(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyuY-r_UnmDB"
   },
   "source": [
    "Now that we have applied the model, we can do some data wrangling to get observed vs predicted labels and then calculate accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wzuu4xlBnDyk"
   },
   "outputs": [],
   "source": [
    "# convert the table to ConfusionMatrix\n",
    "# need to provide which columns are predicted vs observed\n",
    "cm = pred_samples.errorMatrix(actual=\"landcover\",predicted=\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvzx0ky7oJDu"
   },
   "source": [
    "Now we can use EE to calculate common accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lknz87vzoGLw"
   },
   "outputs": [],
   "source": [
    "# call the methods to calculate metrics and get locally\n",
    "overall_acc = cm.accuracy().getInfo()\n",
    "producers_acc = cm.producersAccuracy().getInfo()\n",
    "consumers_acc = cm.consumersAccuracy().getInfo()\n",
    "kappa = cm.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loLXJMiKoheF"
   },
   "outputs": [],
   "source": [
    "print(f\"Overall Accuracy: {overall_acc:.4f}\")\n",
    "print(f\"Producer's Accuracy: {producers_acc}\")\n",
    "print(f\"Consumer's Accuracy: {consumers_acc}\")\n",
    "print(f\"Kappa coefficient: {kappa:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNs3soHzEUCGT1X6NnOVt6K",
   "collapsed_sections": [],
   "name": "Lab 7 - Land cover classification.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
