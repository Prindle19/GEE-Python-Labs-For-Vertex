{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhbW1jHZLlPC"
   },
   "source": [
    "# Lab 14: Groundwater monitoring with GRACE\n",
    "\n",
    "**Purpose:** The following tutorial details how to use observations from the Gravity Recovery and Climate Experiment (GRACE) to evaluate changes in groundwater storage for a large river basin. Here, you will learn how to apply remote sensing estimates of total water storage anomalies, land surface model output, and in situ observations to resolve groundwater storage changes in California’s Central Valley. The following method has been applied to study water storage changes around the world and can be ported to quantify groundwater storage change for major river basins.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1TdjRcjM-WI"
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQjeaoZYMrh9"
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from geemap import colormaps as cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qitu8Ml0Mrer"
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQHeBC4KSVnr"
   },
   "source": [
    "## Background\n",
    "\n",
    "Since 2002, the Gravity Recovery and Climate Experiment (GRACE) and the follow-on mission, GRACE-FO, have provided a new vantage to track changes in water resources (Tapley et al. 2004). GRACE holds the unique ability to directly track changes in total water storage anomalies (TWSa), according to the following equation:\n",
    "\n",
    "$TWSa = CANa + SMa + SWa + SWEa + GWa$\n",
    "\n",
    "where $CANa$ is canopy water storage anomaly, $SMa$ is the soil moisture anomaly, $SWa$ is the surface water anomaly, $SWEa$ is the snow water equivalent anomaly, and $GWa$ is the groundwater storage anomaly. By incorporating supplemental observations from other remote sensing platforms and land surface models and rearranging the equation, scientists have been able to resolve changes in groundwater storage within major river basins around the planet (Famiglietti et al. 2014). From Bangladesh (Purdy et al. 2019) and India (Rodell et al. 2009) to the Middle East (Voss et al. 2013) and the American Southwest (Castle et al. 2014), declining groundwater storage changes have emerged with varying levels of severity (Richey et al. 2015). Like many other regions around the world, California shares the problem of groundwater overreliance (Famiglietti et al. 2011). This tutorial demonstrates  the analytical steps to resolve groundwater storage changes using GRACE for California’s Central Valley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5Ydok4QS0oM"
   },
   "source": [
    "## Define AOI - Central Valley\n",
    "\n",
    "Our area of interes is the Central Valley in California. This area is home to California's major mountain water source, the snowpack of the Sierra Nevada range. The Central Valley is the most productive agricultural region in the U. S., growing 8 percent of the food produced in the U. S. by value ([Faunt, 2009](https://pubs.usgs.gov/pp/1766/)). It accounts for 1/6 of the country's irrigated land and supplies 1/5 of the demand for groundwater in the United States. The area is the second most pumped aquifer in the U. S. after the High Plains aquifer making it an interesting study area for groundwater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaAIqLNWSTEL"
   },
   "outputs": [],
   "source": [
    "# Import Basins\n",
    "basins = ee.FeatureCollection(\"USGS/WBD/2017/HUC04\");\n",
    "\n",
    "\n",
    "# filter basins to the Central Valley\n",
    "# Extract the 3 HUC 04 basins for the Central Valley\n",
    "central_valley = basins.filter(\n",
    "    ee.Filter.Or(\n",
    "        ee.Filter.eq('huc4','1802'),\n",
    "        ee.Filter.eq('huc4','1803'),\n",
    "        ee.Filter.eq('huc4','1804')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddxteRLTLOSG"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(central_valley, 6); \n",
    "\n",
    "Map.addLayer(central_valley,{},\"Central Valley\")\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XFBKIlDtOkC"
   },
   "source": [
    "### Import GRACE Data and display Total Water Storage\n",
    "\n",
    "GRACE can directly track changes in total water storage anomalies (TWSa). Changes in TWSa indicate which regions are gaining or losing water. Remember there are multiple GRACE solutions but we will use the Mascon with coastal resolution improvements (CRI) ([Wiese et al., 2016]( https://doi.org/10.1002/2016WR019344)).\n",
    "\n",
    "We will import the GRACE collection and calculate the average change in TWSa for 2003-2016 as well as extract a time series for the Central Valley area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FGuSxbD40BT"
   },
   "outputs": [],
   "source": [
    "# define start time\n",
    "start_time = ee.Date(\"2003-01-01\")\n",
    "end_time = ee.Date(\"2017-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsE0O5-ZuNiE"
   },
   "outputs": [],
   "source": [
    "grace = ee.ImageCollection(\"NASA/GRACE/MASS_GRIDS/MASCON_CRI\").filterDate(start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VStngKSG06i"
   },
   "source": [
    "The GRACE data imported here have already been processed to provide units of total water storage anomalies. The data contained in this dataset are units of \"equivalent water thickness\" anomalies. However, we need to apply a gain (scale) factor to the data so that we can accurately compare to hydrologic trends ([Landerer & Swenson, 2012](https://doi.org/10.1029/2011WR011453)).\n",
    "\n",
    "There is a file on Learning Suite for you to upload and use, otherwise load in the file shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdyzkMHOCVWY"
   },
   "outputs": [],
   "source": [
    "# load in the gain factor image\n",
    "# change to the asset path that you uploaded\n",
    "gain_factor = ee.Image(\"users/kmarkert/BYUCE594/CLM4_SCALE_FACTOR_JPL_MSCNv02CRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUBZcK1tuPnI"
   },
   "outputs": [],
   "source": [
    "# function to apply gain to each image\n",
    "def apply_gain(img):\n",
    "    return img.multiply(gain_factor).copyProperties(img,[\"system:time_start\"])\n",
    "\n",
    "# select the GRACE liquid water equivalent data and apply gain factor\n",
    "twsa = grace.select('lwe_thickness').map(apply_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCCXTJ1cvhGg"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(central_valley, 6); \n",
    "\n",
    "Map.addLayer(twsa.mean(),{\"min\":-10,\"max\":10,\"palette\":cmaps.get_palette(\"Spectral\")}, \"Total Water Storage anomaly\", opacity=0.75)\n",
    "Map.addLayer(central_valley,{},\"Central Valley\")\n",
    "\n",
    "Map.add_colorbar({\"min\":-10,\"max\":10,\"palette\":cmaps.get_palette(\"Spectral\")}, label=\"LWE [cm]\")\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XRvWG36uhwq"
   },
   "outputs": [],
   "source": [
    "# define a function that will calculate per-band average values for Central Valley\n",
    "# and set the averages to the image\n",
    "def calc_timeseries(img):\n",
    "    val = img.reduceRegion(\n",
    "        reducer = ee.Reducer.mean(),\n",
    "        geometry = central_valley.geometry(1e4),\n",
    "        scale = img.select([0]).projection().nominalScale()\n",
    "    )\n",
    "\n",
    "    return img.set(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwTbbyafu1VJ"
   },
   "outputs": [],
   "source": [
    "# get the time series to total water storage\n",
    "twsa_timeseries = twsa.map(calc_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjUb4lrdu97w"
   },
   "outputs": [],
   "source": [
    "# extract out the timeseries information from the collection\n",
    "timeseries = twsa_timeseries.aggregate_array(\"lwe_thickness\").getInfo()\n",
    "timestamp = twsa_timeseries.aggregate_array(\"system:time_start\").getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXZSe3Awwqjv"
   },
   "outputs": [],
   "source": [
    "# convert the data into a pandas DataFrame\n",
    "dates = pd.to_datetime(np.array(timestamp)*1e6)\n",
    "twsa_series = pd.Series(timeseries,index=dates,name=\"TWSa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivuxDtWUwwLj"
   },
   "outputs": [],
   "source": [
    "ax = twsa_series.plot(figsize=(10,7));\n",
    "ax.hlines(0, twsa_series.index[0], twsa_series.index[-1],ls='--',color=\"k\")\n",
    "ax.set_ylabel(\"TWS anomaly [cm]\")\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1OYasXNufzJ"
   },
   "source": [
    "### Estimate the Linear Trend in TWSa Over Time\n",
    "\n",
    "GRACE data only calculates the anomalies (difference from mean) and does not measure total/absolute water storage. However, we can quantify when mass changes and by how much over a long time period and we will do that here by estimating the trend in time for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEpM5W6ruWHR"
   },
   "outputs": [],
   "source": [
    "# define a function that adds the coefficients needed for regression\n",
    "def add_variables(img):\n",
    "    # Compute time in fractional years since the epoch.\n",
    "    date = img.date()\n",
    "    time = date.difference(start_time, 'year')\n",
    "    const = ee.Image.constant(1)\n",
    "    return img.addBands(ee.Image(time).float().rename(\"time\")).addBands(const)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lgZ0YiG5FgZ"
   },
   "outputs": [],
   "source": [
    "# add the coefficients for regression to the images\n",
    "twsa_time = twsa.map(add_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULBeAWQJ5ZdJ"
   },
   "outputs": [],
   "source": [
    "# List of the independent variable names\n",
    "independents = ee.List(['constant', 'time'])\n",
    "\n",
    "# Name of the dependent variable.\n",
    "dependent = ee.String('lwe_thickness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZHgqlAy5hpJ"
   },
   "outputs": [],
   "source": [
    "# Compute a linear trend.  This will have two bands: 'residuals' and \n",
    "# a 2x1 band called coefficients (columns are for dependent variables).\n",
    "twsa_trend = (\n",
    "    twsa_time\n",
    "    .select(independents.add(dependent))\n",
    "    .reduce(ee.Reducer.linearRegression(independents.length(), 1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-PM9rg85prD"
   },
   "source": [
    "The coefficients image is a two-band array image in which each pixel contains values for the slope and offset. We will need convert the array to an image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjaoy_sq5oGZ"
   },
   "outputs": [],
   "source": [
    "# Flatten the coefficients into a 2-band image\n",
    "coefficients = (\n",
    "    twsa_trend\n",
    "    .select('coefficients')\n",
    "    .arrayProject([0])\n",
    "    .arrayFlatten([independents])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIjbzlk-5vkZ"
   },
   "source": [
    "Next, you can visualize the GRACE trends to capture the spatial scales on which GRACE can resolve TWSa. GRACE is adept at capturing these changes *only for larger basins*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqYtz-8P5uDR"
   },
   "outputs": [],
   "source": [
    "# Create a layer of the TWSa slope to add to the map\n",
    "slope = coefficients.select('time');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGIvy4NX54-R"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(central_valley, 6); \n",
    "\n",
    "Map.addLayer(slope.clip(central_valley), {\"min\": -3.5, \"max\": 3.5, \"palette\":cmaps.get_palette(\"bwr_r\")}, 'TWSa Trend', opacity=0.75);\n",
    "Map.addLayer(central_valley,{},\"Central Valley\",opacity=0.2)\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqdnPPSh7DUC"
   },
   "source": [
    "The slope layer reveals that the southern basins (Tulare and San Joaquin) experiences the largest negative changes in TWSa over the time period.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdJRYxDZ7T2J"
   },
   "source": [
    "### Calculating surface storage changes\n",
    "\n",
    "As mentioned, GRACE calcualtes the total water storage anomalies. Therefore, to extract out the groundwater signal, we will need to remove the signal from other storage changes. This is typically done by calculating the surface storage anomalies from the Global Land Data Assimilation System (GLDAS) data.\n",
    "\n",
    "GLDAS comes at 3hr temporal resolution and it the absolute values (e.g. mm) of storage so to compare with GRACE we will need to perform some temporal averaging and calculate the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvUyRzADqJfr"
   },
   "outputs": [],
   "source": [
    "# get the grace image time windows \n",
    "ts = grace.aggregate_array(\"system:time_start\")\n",
    "te = grace.aggregate_array(\"system:time_end\")\n",
    "\n",
    "# calculate how many images there are and get a list to iterate over\n",
    "n = ts.length()\n",
    "iter = ee.List.sequence(0,n.subtract(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pD4xINGFich"
   },
   "outputs": [],
   "source": [
    "# define the bands from GLDAS that we want to use \n",
    "swe_bands = ee.List([\"SWE_inst\"])\n",
    "canopy_bands = ee.List([\"CanopInt_inst\"])\n",
    "soil_bands = ee.List([\"SoilMoi0_10cm_inst\",\"SoilMoi10_40cm_inst\",\"SoilMoi40_100cm_inst\",\"SoilMoi100_200cm_inst\"])\n",
    "\n",
    "bands_select = swe_bands.cat(canopy_bands).cat(soil_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYIQ5bIu6p_S"
   },
   "outputs": [],
   "source": [
    "# load in the GLDAS collection\n",
    "# filter by time\n",
    "# select only the surface storage bands of interes\n",
    "gldas = (\n",
    "    ee.ImageCollection(\"NASA/GLDAS/V021/NOAH/G025/T3H\")\n",
    "    .filterDate(start_time, end_time)\n",
    "    .select(bands_select)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axSlfrNEosdw"
   },
   "outputs": [],
   "source": [
    "# function to calculate surface storages at GRACE time periods\n",
    "def calc_surface_storage(i):\n",
    "    # get the time window from GRACE time info\n",
    "    t1 = ee.Date(ts.get(i))\n",
    "    t2 = ee.Date(te.get(i))\n",
    "\n",
    "    # filter by time window and calculate average\n",
    "    storages = gldas.filterDate(t1,t2).mean()\n",
    "    # extract out specific components and rename\n",
    "    # we will sum for the soil column though\n",
    "    soil_storage = storages.select(soil_bands).reduce(\"sum\").rename(\"soil\")\n",
    "    snow_storage = storages.select(swe_bands).rename(\"snow\")\n",
    "    canopy_storage = storages.select(canopy_bands).rename(\"canopy\")\n",
    "\n",
    "    # kg/m^2 to cm\n",
    "    conversion = 0.1\n",
    "\n",
    "    # combine the surface storage components and set time info\n",
    "    return (\n",
    "        ee.Image.cat([\n",
    "            soil_storage, \n",
    "            snow_storage, \n",
    "            canopy_storage\n",
    "        ])\n",
    "        .multiply(conversion)\n",
    "        .set(\"system:time_start\", t1.millis(), \"system:time_end\", t2.millis())\n",
    "    )\n",
    "   \n",
    "# apply calculation of monthly surface storages\n",
    "surface_storages = ee.ImageCollection.fromImages(iter.map(calc_surface_storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPbI1j1LHFcE"
   },
   "source": [
    "To calculate anomalies (i.e. difference from mean) we need to calculate the mean storage for a baseline (or reference) period. This period should align with the GRACE baseline period so we are comparing the anomalies from the same time period. The [GRACE page](https://grace.jpl.nasa.gov/data/get-data/jpl_global_mascons/) it specifies the baseline as 2004-2009 so we will use the baseline this baseline. However, this baseline can easily change if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHAnwSRklVLl"
   },
   "outputs": [],
   "source": [
    "# set baseline start and end time to calculate anomalies\n",
    "baseline_start = ee.Date(\"2004-01-01\")\n",
    "baseline_end = ee.Date(\"2010-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSSbcnbIr7NU"
   },
   "outputs": [],
   "source": [
    "# calculate average values for the storage components\n",
    "storage_averages = surface_storages.filterDate(baseline_start, baseline_end).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiBLysB423dd"
   },
   "source": [
    "Now we can calculate the anomalies by simply subtracting the mean values from the surface storage components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TN_hpb7ZwYrz"
   },
   "outputs": [],
   "source": [
    "# function to remove baseline mean\n",
    "def calc_anomaly(img):\n",
    "    anomaly = img.subtract(storage_averages)\n",
    "    return anomaly.copyProperties(img, [\"system:time_start\"])\n",
    "\n",
    "# apply function to calculate anomalies\n",
    "surface_anomalies = surface_storages.map(calc_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTb3LqsssUY9"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(central_valley, 6); \n",
    "\n",
    "Map.addLayer(surface_anomalies.mean(), {\"min\": -1.5, \"max\": 1.5}, 'SSa Trend', opacity=0.75);\n",
    "Map.addLayer(central_valley,{},\"Central Valley\",opacity=0.2)\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUh35pvDKZoe"
   },
   "source": [
    "To confirm we have our time series of anomalies, we will plot the series for Central Valley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MVGmMVO65PD"
   },
   "outputs": [],
   "source": [
    "# apply our time series function for Central Valley\n",
    "surface_anomlay_ts = surface_anomalies.map(calc_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GByYh8o7FN8"
   },
   "outputs": [],
   "source": [
    "# extract out the timeseries information from the collection\n",
    "snow_ts = surface_anomlay_ts.aggregate_array(\"snow\").getInfo()\n",
    "soil_ts = surface_anomlay_ts.aggregate_array(\"soil\").getInfo()\n",
    "canopy_ts = surface_anomlay_ts.aggregate_array(\"canopy\").getInfo()\n",
    "timestamp = surface_anomlay_ts.aggregate_array(\"system:time_start\").getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5377K9jN7IyT"
   },
   "outputs": [],
   "source": [
    "# convert the data into a pandas DataFrame\n",
    "dates = pd.to_datetime(np.array(timestamp)*1e6)\n",
    "surface_series = pd.DataFrame({\"soil_anomaly\": soil_ts, \"snow_anomaly\": snow_ts, \"canopy_anomaly\":canopy_ts},index=dates,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auGrzsQm7I5W"
   },
   "outputs": [],
   "source": [
    "# plot the timeseries\n",
    "axs = surface_series.plot(figsize=(10,7),subplots=True);\n",
    "for ax in axs:\n",
    "    ax.hlines(0, surface_series.index[0], surface_series.index[-1],ls='--',color=\"k\")\n",
    "    ax.set_ylabel(\"Storage anomaly [cm]\")\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WEA7djk7RBj"
   },
   "source": [
    "### Extracting out signals of GroundWater changes\n",
    "\n",
    "Now that we have the anomalies for the different surface water components, we remove that signal from the total water storage anomalies to get the groundwater storage anomalies. To do this efficiently, we will join the two collections based on time. Since we used the same time ranges to calculate the surface storage anomalies, the time should line up nicely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qU3PW4kALdiu"
   },
   "source": [
    "To apply the join, we will create a filter based on time. We will set this to a ten day window just to be safe and make sure we join the data we need correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nM0X4Gps6g3"
   },
   "outputs": [],
   "source": [
    "# Define an allowable time difference: ten days in milliseconds.\n",
    "ten_day_millis = 24 * 60 * 60 * 1000 * 10\n",
    "\n",
    "# Create a time filter to define a match as overlapping timestamps.\n",
    "time_filter = ee.Filter.Or(\n",
    "    # use max difference filter to specify only one day difference\n",
    "    # checks one day on either side of observation\n",
    "    ee.Filter.maxDifference(\n",
    "        difference= ten_day_millis,\n",
    "        leftField= 'system:time_start',\n",
    "        rightField= 'system:time_start'\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pg2WiuiUstY4"
   },
   "source": [
    "Now that we have a filter, we need to define our join. This specifies what the results property name will be (in this case `surface_storages`) so we know what to look for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lo4BssVZy-hD"
   },
   "outputs": [],
   "source": [
    "# Define the join.\n",
    "# this is \"saveBest\" which will give us the image closest in time to what we want\n",
    "storages_join = ee.Join.saveBest(\n",
    "  matchKey= 'surface_storages', # this will be the name of the result in the collection\n",
    "  measureKey= 'timeDiff'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ih6hup2tzCIy"
   },
   "outputs": [],
   "source": [
    "# Apply the join.\n",
    "# uses soil_moisture as the collection to join to and applies filter on surface reflectance data\n",
    "joined_storages = ee.ImageCollection(storages_join.apply(twsa, surface_anomalies, time_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFrMUMNIr4to"
   },
   "source": [
    "Lastly, let's compute groundwater water storage changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AS6pUxINzYkE"
   },
   "outputs": [],
   "source": [
    "# function to calculate ground water storage anomalies\n",
    "# by subtracting the surface water anomalies\n",
    "def extract_groundwater(img):\n",
    "    surface_anomalies = ee.Image(img.get(\"surface_storages\")).reduce(\"sum\")\n",
    "    return img.resample().subtract(surface_anomalies).copyProperties(img, [\"system:time_start\"])\n",
    "\n",
    "# apply the calculation for groundwater storage\n",
    "gwsa = joined_storages.map(extract_groundwater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHHBHcrPz3qP"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(central_valley, 6); \n",
    "\n",
    "Map.addLayer(gwsa.mean(), {\"min\": -10, \"max\": 10, \"palette\":cmaps.get_palette(\"Spectral\")}, 'GWSa', opacity=0.75);\n",
    "Map.addLayer(central_valley,{},\"Central Valley\",opacity=0.2)\n",
    "\n",
    "Map.add_colorbar({\"min\": -10, \"max\": 10, \"palette\":cmaps.get_palette(\"Spectral\")}, label=\"Groundwater anomaly [cm]\")\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2fV6ArM8-bK"
   },
   "source": [
    "### Groundwater trends\n",
    "\n",
    "Now that we have a collection of the groundwater storage anomalies, we can calculate a time series for the region of interest. We will focus our analysis on a drought period 2006-2011. This is a similar analysis to [Famiglietti et al.(2011)]( https://doi.org/10.1029/2010GL046442) so we can compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJB4I2xnO96G"
   },
   "outputs": [],
   "source": [
    "# define drought start/end dates\n",
    "drought_start = ee.Date(\"2006-04-01\")\n",
    "drought_end = ee.Date(\"2010-04-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cndi-VMz2UMI"
   },
   "outputs": [],
   "source": [
    "# filter dates and add time information\n",
    "gwsa_time = gwsa.filterDate(drought_start,drought_end).map(add_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P458cQeg9CNd"
   },
   "outputs": [],
   "source": [
    "# Compute a linear trend.  This will have two bands: 'residuals' and \n",
    "# a 2x1 band called coefficients (columns are for dependent variables).\n",
    "gwsa_trend = (\n",
    "    twsa_time\n",
    "    .select(independents.add(dependent))\n",
    "    .reduce(ee.Reducer.linearRegression(independents.length(), 1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OoZnWUDM9GjL"
   },
   "outputs": [],
   "source": [
    "# Flatten the coefficients into a 2-band image\n",
    "coefficients = (\n",
    "    gwsa_trend\n",
    "    .select('coefficients')\n",
    "    .arrayProject([0])\n",
    "    .arrayFlatten([independents])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j35Klck19L4c"
   },
   "outputs": [],
   "source": [
    "# Create a layer of the TWSa slope to add to the map\n",
    "slope = coefficients.select('time');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4WDen4q9O_C"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(central_valley, 6); \n",
    "\n",
    "Map.addLayer(slope.clip(central_valley), {\"min\": -3.5, \"max\": 3.5, \"palette\":cmaps.get_palette(\"bwr_r\")}, 'GWSa Trend', opacity=0.75);\n",
    "Map.addLayer(central_valley,{},\"Central Valley\",opacity=0.2)\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50WMM_bPOUoG"
   },
   "outputs": [],
   "source": [
    "cv_slope = slope.reduceRegion(\n",
    "    reducer = ee.Reducer.mean(),\n",
    "    geometry = central_valley.geometry(1e4),\n",
    "    scale=slope.projection().nominalScale()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gk6pDvvmOneG"
   },
   "outputs": [],
   "source": [
    "rate = cv_slope.get(\"time\").getInfo()\n",
    "\n",
    "print(f\"Average Central Valley GWSa rate of change: {rate:.4f} cm/yr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqLQOuym0P2d"
   },
   "outputs": [],
   "source": [
    "# apply time series calculation over Central Valley\n",
    "gwsa_timeseries = gwsa_time.map(calc_timeseries).filter(ee.Filter.neq(\"lwe_thickness\",None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-GfUvCq2FJ5"
   },
   "outputs": [],
   "source": [
    "# extract out the timeseries information from the collection\n",
    "timeseries = gwsa_timeseries.aggregate_array(\"lwe_thickness\").getInfo()\n",
    "year = gwsa_timeseries.aggregate_array(\"time\").getInfo()\n",
    "timestamp = gwsa_timeseries.aggregate_array(\"system:time_start\").getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPHGhPZV2Jhp"
   },
   "outputs": [],
   "source": [
    "# convert the data into a pandas DataFrame\n",
    "dates = pd.to_datetime(np.array(timestamp)*1e6)\n",
    "gwsa_drought_df = pd.DataFrame({\"GWSa\": timeseries, \"year\": year},index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XQHeicF-mla"
   },
   "outputs": [],
   "source": [
    "regression = stats.linregress(gwsa_drought_df[\"year\"], gwsa_drought_df[\"GWSa\"])\n",
    "\n",
    "gwsa_drought_df[\"trend\"] = gwsa_drought_df[\"year\"] * regression[0] + regression[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N1B5Scx2Om_"
   },
   "outputs": [],
   "source": [
    "ax = gwsa_drought_df[[\"GWSa\",\"trend\"]].plot(figsize=(10,7));\n",
    "ax.hlines(0, gwsa_drought_df.index[0], gwsa_drought_df.index[-1],ls='--',color=\"k\")\n",
    "ax.set_ylabel(\"GWS anomaly [cm]\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPMh-bp0tbW3"
   },
   "outputs": [],
   "source": [
    "print(f\"Calculated Central Valley GWSa rate of change: {regression[0]:.4f} cm/yr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmz1L-ipun5Y"
   },
   "source": [
    "Based on the calculated rates of change, there was is a high reliance on groundwater. Another paper, [Famiglietti et al., 2011]( https://doi.org/10.1029/2010GL046442) calculated the change as  -3.89 ± 0.95 cm/yr, whereas our estimates were lower when caculating the slope then averaging and higher when averaging then calculating slope. However, in their paper they only used the Sacramento and San Joaquin River Basins (top two basins) whereas we used all three basins covering Central Valley and applied the gain factors for comparing to hydrologic data. \n",
    "\n",
    "Funny enough, if you average the two rates of change calculated then you get the same answer as Famiglietti et al., 2011...."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP+Q4vqiZCvKBlO3e5jSOKC",
   "collapsed_sections": [],
   "name": "Lab 14 - Groundwater monitoring with GRACE.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
