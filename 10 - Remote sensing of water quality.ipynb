{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYf57bJYnDT0"
   },
   "source": [
    "# Lab 10: Remote sensing of water quality\n",
    "\n",
    "**Purpose:** The purpose of this lab is to walk through an example of using remote sensing datasets for water quality monitoring. Students will gain experience using Earth Engine for spatial-temporal data sampling as well as regression analysis for estimating a water quality parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8G5_zUdnMiC"
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDywqoH0nKqd"
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geemap import colormaps as cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_hy1ThmmsPa"
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQaATf9snRBB"
   },
   "source": [
    "## Background\n",
    "\n",
    "Remote sensing tools can provide spatial and temporal resolution for monitoring water quality in reservoirs and large rivers that are not available from traditional in situ measurements. The retrieval of water quality parameters from remote sensing systems relies on the optical properties (transmittance, absorption and scattering) of water and the dissolved and suspended constituents in the water. Suspended solids are responsible for most of the scattering in an aquatic system, whereas chlorophyll-a (chl-a) and colored dissolved matter are mainly responsible for absorption ([Myint and Walker, 2002](https://doi.org/10.1080/01431160110104700\n",
    ")). There is a wide body of research on assessing water quality analytical optical modeling using in situ inherent optical properties ([Cox et al., 2009](https://doi.org/10.1080/07438149809354347)). Methods used to relate in situ data to the satellite observations through statistical relationships include simple linear regression, non-linear regressions, principal component analysis, and neural networks.\n",
    "\n",
    "In this notebook, we will explore a straightforward empirical approach using a linear regression to estimate a water quality for lakes and reservoirs in Utah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNH9lN3OvRTk"
   },
   "source": [
    "## Estimating water quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVaAUwExlCif"
   },
   "source": [
    "For this example, we are going to estimate [Secchi depth](https://en.wikipedia.org/wiki/Secchi_disk) from remote sensing data. Secchi depth is an optical property of water which is related to turbidity and other water quality parameters ([Lavender et al., 2017](https://doi.org/10.1371/journal.pone.0186092)). Of course, to estimate this parameter we need field measurements and relate those to what is observed by satellites. The data used in this notebook was collected from the [Water Quality Data Viewer App](https://tethys-staging.byu.edu/apps/lake/data/) and uploaded to Earth Engine.\n",
    "\n",
    "To start, we will do some pre-processing to the water quality sample table and remote sensing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Whami0vDnRRZ"
   },
   "outputs": [],
   "source": [
    "# load in our data set\n",
    "utah_secchi = ee.FeatureCollection(\"users/kmarkert/BYUCE594/Utah_Lake_Secchi_depth\")\n",
    "gsl_secchi = ee.FeatureCollection(\"users/kmarkert/BYUCE594/GSL_Secchi_depth\")\n",
    "dc_secchi = ee.FeatureCollection(\"users/kmarkert/BYUCE594/Deer_Creek_Secchi_depth\")\n",
    "\n",
    "wq_samples = utah_secchi.merge(gsl_secchi).merge(dc_secchi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eG4CUNz1p1JA"
   },
   "outputs": [],
   "source": [
    "print(f\"Total number of samples: {wq_samples.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AN8lnYgtoGm3"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(wq_samples, 9); \n",
    "\n",
    "Map.addLayer(wq_samples,{},\"Water Quality Samples\")\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHrhwyCbsNBm"
   },
   "outputs": [],
   "source": [
    "# define function to format date information for samples\n",
    "def format_sample_date(feature):\n",
    "    # extract date info and convert to milliseconds since 1970\n",
    "    collection_time = ee.Date.parse(\"MM-dd-YYYY\", feature.get(\"Activity Start Date\")).millis()\n",
    "    return feature.set(\"collection_date\",collection_time)\n",
    "\n",
    "wq_samples = wq_samples.map(format_sample_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNnGf2tEslbl"
   },
   "outputs": [],
   "source": [
    "# display the information from first feature\n",
    "wq_samples.first().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuLfnndD5Oux"
   },
   "source": [
    "Next we need remote sesning data. For this example we will use Landsat as it provides a long time series of satellite observations. We will have to do some preprocessing before using and combine collections from different sensor collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccx7FJ5hT3A8"
   },
   "outputs": [],
   "source": [
    "# load historical suface water occurrence information to constain water masks\n",
    "water_occurrence = ee.Image(\"JRC/GSW1_3/GlobalSurfaceWater\").select(\"occurrence\")\n",
    "water_constrain = water_occurrence.gt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpUZ9biGkznL"
   },
   "outputs": [],
   "source": [
    "# QA mask function\n",
    "def qa_mask(image):\n",
    "    #Bits 3, 4, and 5 are cloud shadow, snow, and cloud, respectively.\n",
    "    cloudShadowBitMask = (1 << 3);\n",
    "    cloudsBitMask = (1 << 5);\n",
    "    snowBitMask = (1 << 4);\n",
    "\n",
    "    #Get the pixel QA band.\n",
    "    qa = image.select('pixel_qa');\n",
    "\n",
    "    # apply the bit shift and get binary image of different QA flags\n",
    "    cloud_shadow_qa = qa.bitwiseAnd(cloudShadowBitMask).eq(0)\n",
    "    snow_qa = qa.bitwiseAnd(snowBitMask).eq(0)\n",
    "    cloud_qa = qa.bitwiseAnd(cloudsBitMask).eq(0)\n",
    "\n",
    "    # get water mask info!\n",
    "    waterBitMask = (1 << 2)\n",
    "    # and constrain to where we know there is water\n",
    "    water_qa = qa.bitwiseAnd(waterBitMask).updateMask(water_constrain)\n",
    "\n",
    "    # combine qa mask layers to one final mask\n",
    "    mask = cloud_shadow_qa.And(snow_qa).And(cloud_qa).And(water_qa)\n",
    "\n",
    "    # apply mask and return orignal image\n",
    "    return image.updateMask(mask);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmZUzGC4z7sR"
   },
   "outputs": [],
   "source": [
    "# load on Landsat 5 collection\n",
    "l5_collection = (\n",
    "    ee.ImageCollection('LANDSAT/LT05/C01/T1_SR')\n",
    "    # filter by sample locations\n",
    "    .filterBounds(wq_samples)\n",
    "    # apply qa mask\n",
    "    .map(qa_mask)\n",
    "    # select the spectral bands and rename\n",
    "    .select(\n",
    "        [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B7\"],\n",
    "        [\"blue\",\"green\",\"red\",\"nir\",\"swir1\",\"swir2\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0m7Tmb3sz-ox"
   },
   "outputs": [],
   "source": [
    "# load on Landsat 7 collection\n",
    "l7_collection = (\n",
    "    ee.ImageCollection('LANDSAT/LE07/C01/T1_SR')\n",
    "    # filter by sample locations\n",
    "    .filterBounds(wq_samples)\n",
    "    # apply qa mask\n",
    "    .map(qa_mask)\n",
    "    # select the spectral bands and rename\n",
    "    .select(\n",
    "        [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B7\"],\n",
    "        [\"blue\",\"green\",\"red\",\"nir\",\"swir1\",\"swir2\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNCMFlL7sJWp"
   },
   "outputs": [],
   "source": [
    "# load on Landsat 8 collection\n",
    "l8_collection = (\n",
    "    ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "    # filter by sample locations\n",
    "    .filterBounds(wq_samples)\n",
    "    # apply qa mask\n",
    "    .map(qa_mask)\n",
    "    # select the spectral bands and rename\n",
    "    .select(\n",
    "        [\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\"],\n",
    "        [\"blue\",\"green\",\"red\",\"nir\",\"swir1\",\"swir2\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5cjMRKx3zKK"
   },
   "outputs": [],
   "source": [
    "# merge all of the collections together for long time series\n",
    "ls_collection = l5_collection.merge(l7_collection).merge(l8_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKDjv6GKxSqR"
   },
   "outputs": [],
   "source": [
    "ls_composite = ls_collection.median()\n",
    "ls_count = ls_collection.select(\"blue\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_kqmx2yxO0t"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(wq_samples, 9); \n",
    "\n",
    "Map.addLayer(ls_composite, {\"bands\":\"red,green,blue\", \"min\": 0, \"max\": 3300,\"gamma\":1.3}, 'L8 Composite');\n",
    "Map.addLayer(ls_count, {\"min\": 0, \"max\": 1000,\"palette\":cmaps.get_palette(\"magma\")}, 'Observation Count');\n",
    "\n",
    "Map.addLayer(wq_samples,{},\"Water Quality Samples\")\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MY4xqQZtWOL"
   },
   "source": [
    "### Sampling coincident data\n",
    "\n",
    "Here we are going to do the unthinkable...use a for loop! But we are going to try to be smart about how we set this up: first we will identify all unique dates that samples were collected (this limits the number of loops) and then sample from our imagery using all sampels from the dates. Additionally, we will wrap different requests in the loop so that this doesn't happen on the server side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EaZk-jdtk_1"
   },
   "outputs": [],
   "source": [
    "# get list of unique dates for samples\n",
    "dates = (\n",
    "    wq_samples\n",
    "    .aggregate_array(\"collection_date\") # get the date information \n",
    "    .map(lambda x: ee.Date(x).format(\"YYYY-MM-dd\")) # convert the date object to ISO string\n",
    "    .distinct() # only get unique date values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ki_1l3m1uJmc"
   },
   "outputs": [],
   "source": [
    "# get how many dates we have to loop through\n",
    "n = dates.size().getInfo()\n",
    "\n",
    "print(f\"Number of collection dates: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5h59GsJ-j6P"
   },
   "source": [
    "Must be careful with sampling using this approach...it is very easy to get a `Maximum recursion depth exceeded` error which means that too many request attempts were nested. To avoid the error then we can set our recursion depth to higher than the default system setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mm7QCPOlIZNb"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpqolp6UhfF3"
   },
   "source": [
    "Now we are ready to run the sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IN6Jsw_tR3R"
   },
   "outputs": [],
   "source": [
    "# create an empty featurecollection to append samples to\n",
    "rs_wq_samples = ee.FeatureCollection([])\n",
    "\n",
    "# coincident tolerance in days\n",
    "# controls how many days on either side of sample collection to check for RS data\n",
    "tolerance = 1\n",
    "\n",
    "# start looping over dates\n",
    "for i in range(n):\n",
    "    collection_date = ee.Date(dates.get(i))\n",
    "\n",
    "    # get time bounds to filter imagery\n",
    "    t1 = collection_date.advance(-tolerance,\"day\")\n",
    "    t2 = collection_date.advance(tolerance+1,\"day\")\n",
    "\n",
    "    # get the samples from the date of interest\n",
    "    samples_date = wq_samples.filter(ee.Filter.eq(\"collection_date\",collection_date.millis()))\n",
    "\n",
    "    # filter imagery for date and mosaic\n",
    "    sample_img = ls_collection.filterDate(t1,t2).mosaic()\n",
    "\n",
    "    # sample pixels using the sample points\n",
    "    spectra_samples = sample_img.sampleRegions(\n",
    "        collection=samples_date,\n",
    "        scale = 30, \n",
    "        tileScale = 4, \n",
    "        geometries = True\n",
    "    )\n",
    "\n",
    "    # append samples from date to larger collection\n",
    "    rs_wq_samples = rs_wq_samples.merge(spectra_samples)\n",
    "\n",
    "# filter by a band to make sure we only have samples from valid obs\n",
    "rs_wq_samples = rs_wq_samples.filter(ee.Filter.neq(\"blue\",None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdzpTAb2q0zL"
   },
   "source": [
    "Because sampling is a computationally process (we have to pre-process all of the imagery and then find coincident observations), we typically export this intermediate result to load in later. We can theoretically continue using the sampled collection in interactive mode but it is very likely we will run into a `Too many concurrent aggregations` error.\n",
    "\n",
    "To export as an asset and as a CSV in Google Drive, we can run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkMuXxAqzMeJ"
   },
   "outputs": [],
   "source": [
    "# Export to asset code\n",
    "userid = geemap.ee_user_id()\n",
    "asset_task = ee.batch.Export.table.toAsset(\n",
    "    collection = rs_wq_samples,\n",
    "    description = \"UT_Lake_WQ_LS_Samples\",\n",
    "    assetId = f\"{userid}/UT_Lake_WQ_LS_Samples\"\n",
    ")\n",
    "asset_task.start()\n",
    "\n",
    "# Export to drive code\n",
    "drive_task = ee.batch.Export.table.toDrive(\n",
    "    collection = rs_wq_samples,\n",
    "    description = \"UT_Lake_WQ_LS_Samples\"\n",
    ")\n",
    "drive_task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWrP5tyaBLye"
   },
   "source": [
    "### Statistical analysis\n",
    "\n",
    "We are going to use Earth Engine to perform some *basic* statistical analysis for estimating Secchi depth. Ideally you would perform a more robust analysis outside of EE (hence why we exported to Drive). However, this provides an example of doing the analysis with Earth Engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6br4joxU1g5"
   },
   "outputs": [],
   "source": [
    "# read in a pre-exported collection to make computations run quicker\n",
    "table = ee.FeatureCollection(\"users/kmarkert/UT_Lake_WQ_LS_Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88SQzD3lMJOO"
   },
   "outputs": [],
   "source": [
    "# define which columns to test correlations with\n",
    "x_cols = ee.List([\"blue\",\"green\",\"red\",\"nir\"])\n",
    "y_col = \"Result Value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTDyn52UDrC4"
   },
   "outputs": [],
   "source": [
    "# define a function to calculate correlations between different\n",
    "# predictor variables and the response\n",
    "def get_correlation(x):\n",
    "    r = table.reduceColumns(ee.Reducer.pearsonsCorrelation(),[x,y_col])\n",
    "    return r.get(\"correlation\")\n",
    "\n",
    "# get correlations\n",
    "cor_list = x_cols.map(get_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iKkokFbfvUX"
   },
   "outputs": [],
   "source": [
    "cor_list.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvI0aoLBC5C3"
   },
   "outputs": [],
   "source": [
    "# determine which column has the best correlations\n",
    "max_cor = ee.Array(cor_list).abs().argmax().get(0)\n",
    "x_col = ee.String(x_cols.get(max_cor))\n",
    "print(f\"Best correlated: '{x_col.getInfo()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2up7OlFuH39o"
   },
   "outputs": [],
   "source": [
    "# define function to add predictor/response variables \n",
    "# to the featurecollection\n",
    "def add_vars(feature):\n",
    "    # extract out cols and apply log transform\n",
    "    y = ee.Number(feature.get(y_col)).log10()\n",
    "    x = ee.Number(feature.get(x_col)).log10()\n",
    "\n",
    "    # pack the info to key-value pairs\n",
    "    var_dict = ee.Dictionary({\n",
    "        \"x\":x,\n",
    "        \"constant\": 1,\n",
    "        \"y\":y\n",
    "    })\n",
    "\n",
    "    # assign new column info\n",
    "    return feature.set(var_dict)\n",
    "\n",
    "# apply function\n",
    "table = table.map(add_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xf90QTpvhhTi"
   },
   "outputs": [],
   "source": [
    "table.first().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0pl-bBIImF1"
   },
   "outputs": [],
   "source": [
    "# apply regression on the table\n",
    "regression = table.reduceColumns(ee.Reducer.linearRegression(numX=2,numY=1),[\"constant\",\"x\",\"y\"])\n",
    "# extract out the coefficients as a list\n",
    "coefficients = ee.Array(regression.get(\"coefficients\")).project([0]).toList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9OK2rVgSExV"
   },
   "outputs": [],
   "source": [
    "coefficients.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWjYECxpoaAG"
   },
   "source": [
    "### Applying regression on imagery\n",
    "\n",
    "Now that we have coefficients for estimating Secchi depth from remote sensing data, we can now apply over all imagery. This is beneficial as it provides spatial estimates of the parameter as well as can be applied for each aquisition (provided there are no clouds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6FAQgFzMZx4"
   },
   "outputs": [],
   "source": [
    "# define function to calculate the secchi depth from coefficients\n",
    "def apply_regression(img):\n",
    "    # extract out band for prediction\n",
    "    # and apply log transform\n",
    "    log_g = img.select(x_col).log10()\n",
    "    # apply regression\n",
    "    log_secchi_depth = log_g.polynomial(coefficients)\n",
    "    # inverse log transform\n",
    "    secchi_depth = ee.Image.constant(10).pow(log_secchi_depth)\n",
    "\n",
    "    return secchi_depth.rename(\"secchi_depth\").copyProperties(img,[\"system:time_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paMg8UZXOrR6"
   },
   "outputs": [],
   "source": [
    "# apply function to calculate secchi depth\n",
    "secchi_depth_collection = ls_collection.map(apply_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-LEHjaNO_m6"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(wq_samples, 9); \n",
    "\n",
    "Map.addLayer(ls_collection.median(), {\"bands\":\"red,green,blue\", \"min\": 0, \"max\": 3300,\"gamma\":1.3}, 'L8 Composite');\n",
    "Map.addLayer(secchi_depth_collection.mean(), {\"min\": 0, \"max\": 2,\"palette\":cmaps.get_palette(\"viridis_r\")}, 'Secchi depth');\n",
    "\n",
    "Map.addLayer(wq_samples,{},\"Water Quality Samples\")\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-FclxCwqoHV"
   },
   "source": [
    "### Quick visualization of analysis\n",
    "\n",
    "Our example on Earth Engine leaves much to be desired in terms of visualizing data for the analysis. So, to illustrate the same analysis on the client-side using Python, we run the regression and plot the results of fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v59CTa92bwZE"
   },
   "outputs": [],
   "source": [
    "# get the column arrays from earth engine\n",
    "x_obs = np.array(table.aggregate_array(x_col).getInfo())\n",
    "y_obs = np.array(table.aggregate_array(y_col).getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbgJtB1_GD7m"
   },
   "outputs": [],
   "source": [
    "# apply log transform on data out\n",
    "x = np.log10(x_obs)\n",
    "y = np.log10(y_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SB-2INeDq4KB"
   },
   "outputs": [],
   "source": [
    "# apply linear fit\n",
    "z = np.polyfit(x,y,1)\n",
    "p = np.poly1d(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wT2J7YcoHAK7"
   },
   "outputs": [],
   "source": [
    "# create an array of x values and predict for visualization\n",
    "x_line = np.log10(np.arange(x_obs.min(), x_obs.max(),1))\n",
    "y_line = p(x_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X1bzLDwZILa"
   },
   "outputs": [],
   "source": [
    "# visualize samples and regression\n",
    "plot(x, y, \"C0o\", alpha=0.3)\n",
    "plot(x_line,y_line,\"C1\",lw=3);\n",
    "xlabel(f\"Log spectra ({x_col.getInfo()})\")\n",
    "ylabel(\"Log Secchi depth\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKcq6wtIF_MC"
   },
   "outputs": [],
   "source": [
    "# apply prediction on real data\n",
    "# and apply inverse log trasform\n",
    "y_hat = 10 ** p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ipRAKaCLb4I"
   },
   "outputs": [],
   "source": [
    "# visualize predicted vs observed\n",
    "plot(y_obs, y_hat, \"C0o\", alpha=0.3)\n",
    "plot([0,y_hat.max()],[0,y_hat.max()],\"k--\")\n",
    "xlabel(\"Observed [m]\")\n",
    "ylabel(\"Predicted [m]\");\n",
    "xlim(0,8)\n",
    "ylim(0,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zgCENm2wZf-"
   },
   "source": [
    "After visualizing the results, this does not provide bad results for the level of effort put into it. Additional statistical analysis would be needed to achieve a better model for estimating Secchi depth, however, the goal of this notebook was not to get a perfectly accurate result but rather demonstrate the process."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyqlcsTPWNmDOhSE90EbJP",
   "collapsed_sections": [],
   "mount_file_id": "1vW6TxUW59jo41slANMEb2FUrn4hHzdOi",
   "name": "Lab 10 - Remote sensing of water quality.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
