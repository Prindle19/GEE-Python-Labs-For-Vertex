{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3sj0mc0BzcF",
    "tags": []
   },
   "source": [
    "# Lab 9: Remote sensing of Surface Water / Floods\n",
    "\n",
    "**Purpose:** The purpose of this lab is to demonstrate, step-by-step, the implementation of an efficient and robust approach for mapping surface water. You will also learn how the extracted surface water information can be used in conjunction with historical surface water information to extract flooded areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYB4YYHfBqzE"
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "import pandas as pd\n",
    "from geemap import colormaps as cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AjGGGGUCyDc"
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYH7mgzoDAOg"
   },
   "source": [
    "## Background\n",
    "\n",
    "An efficient method for mapping water is image thresholding ([Schumann et al. 2009](https://doi.org/10.1109/TGRS.2009.2017937)). There are numerous methods for automated image thresholding, however, a popular method is the Otsu’s method ([Otsu, 1979](https://cw.fel.cvut.cz/b201/_media/courses/a6m33bio/otsu.pdf)). Otsu’s method is a histogram-based thresholding approach where the inter-class variance between two classes, a foreground and background class, is maximized. As stated, this approach assumes only two classes are present within an image which is rarely the case. Therefore, methods have been developed (i.e. [Donchyts et al. 2016](https://doi.org/10.3390/rs8050386) and [Cao et al. 2019](https://doi.org/10.3390/w11040786)) to constrain histogram sampling to areas that are more likely to represent a bimodal histogram of water/no water. The constrained histogram provides a more accurate estimation of a water threshold while not sacrificing the computation efficiency of the Otsu thresholding method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuyrDlSGEFNw"
   },
   "source": [
    "## Surface water mapping\n",
    "\n",
    "To begin we will start with accessing Sentinel-1 data. We will focus our analysis on Southeast Asia which experiences yearly flooding and has plenty of good test cases. To do this, we will assign the Sentinel-1 collection to a variable and filter by space, time, and metadata properties to get our image for processing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WjrmzYHEI6K"
   },
   "source": [
    "### Pre-processing\n",
    "\n",
    "As we explored in [Lab 6](https://colab.research.google.com/drive/1EzuXVxvlkdVPRwS9zbrMFEF_sAcKzvzb?usp=sharing), the SAR data on Earth Engine requires pre-processing which includes radiometric terrain correction and speckle filtering. Here we will define our functions to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZ2kzl6-EEtK"
   },
   "outputs": [],
   "source": [
    "# function to convert power to dB units\n",
    "def power_to_db(image):\n",
    "    return ee.Image.constant(10).multiply(image.log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5I_ZRiiuFwZf"
   },
   "outputs": [],
   "source": [
    "def slope_correction(image):\n",
    "    \"\"\"This function applies the slope correction on a Sentinel-1 image.\n",
    "    Function based on https:# doi.org/10.3390/rs12111867.\n",
    "    Adapted from https:# github.com/ESA-PhiLab/radiometric-slope-correction/blob/master/notebooks/1%20-%20Generate%20Data.ipynb\n",
    "\n",
    "    args:\n",
    "        image (ee.Image): Sentinel-1 to perform correction on\n",
    "        elevation (ee.Image): Input DEM to calculate slope corrections from\n",
    "        model (str, optional): physical reference model to be applied. Options are 'volume' or 'surface'.\n",
    "            default = volume\n",
    "        buffer (int, optional): buffer in meters for layover/shadow mask. If zero then no buffer will be applied. default = 0\n",
    "        scale (int, optional): reduction scale to process satellite heading compared to ground. Increasing will reduce\n",
    "            chance of OOM errors but reduce local scale correction accuracy. default = 1000\n",
    "\n",
    "    returns:\n",
    "        ee.Image: slope corrected SAR imagery with look and local incidence angle bands\n",
    "\n",
    "    raises:\n",
    "        NotImplementedError: when keyword model is not of 'volume' or 'surface'\n",
    "    \"\"\"\n",
    "\n",
    "    def _volumetric_model_SCF(theta_iRad, alpha_rRad):\n",
    "        \"\"\"Closure funnction for calculation of volumetric model SCF\n",
    "\n",
    "        args:\n",
    "            theta_iRad (ee.Image): incidence angle in radians\n",
    "            alpha_rRad (ee.Image): slope steepness in range\n",
    "\n",
    "        returns:\n",
    "            ee.Image\n",
    "        \"\"\"\n",
    "\n",
    "        # model\n",
    "        nominator = (ninetyRad.subtract(theta_iRad).add(alpha_rRad)).tan()\n",
    "        denominator = (ninetyRad.subtract(theta_iRad)).tan()\n",
    "        return nominator.divide(denominator)\n",
    "\n",
    "    def _surface_model_SCF(theta_iRad, alpha_rRad, alpha_azRad):\n",
    "        \"\"\"Closure funnction for calculation of direct model SCF\n",
    "\n",
    "        args:\n",
    "            theta_iRad (ee.Image): incidence angle in radians\n",
    "            alpha_rRad (ee.Image): slope steepness in range\n",
    "            alpha_azRad (ee.Image): slope steepness in azimuth\n",
    "\n",
    "        returns:\n",
    "            ee.Image\n",
    "        \"\"\"\n",
    "\n",
    "        # model\n",
    "        nominator = (ninetyRad.subtract(theta_iRad)).cos()\n",
    "        denominator = alpha_azRad.cos().multiply(\n",
    "            (ninetyRad.subtract(theta_iRad).add(alpha_rRad)).cos()\n",
    "        )\n",
    "\n",
    "        return nominator.divide(denominator)\n",
    "\n",
    "    def _erode(image, distance):\n",
    "        \"\"\"Closure function to buffer raster values\n",
    "\n",
    "        args:\n",
    "            image (ee.Image): image that should be buffered\n",
    "            distance (int): distance of buffer in meters\n",
    "\n",
    "        returns:\n",
    "            ee.Image\n",
    "        \"\"\"\n",
    "\n",
    "        d = (\n",
    "            image.Not()\n",
    "            .unmask(1)\n",
    "            .fastDistanceTransform(10)\n",
    "            .sqrt()\n",
    "            .multiply(ee.Image.pixelArea().sqrt())\n",
    "        )\n",
    "\n",
    "        return image.updateMask(d.gt(distance))\n",
    "\n",
    "    def _masking(alpha_rRad, theta_iRad, buffer):\n",
    "        \"\"\"Closure function for masking of layover and shadow\n",
    "\n",
    "        args:\n",
    "            alpha_rRad (ee.Image): slope steepness in range\n",
    "            theta_iRad (ee.Image): incidence angle in radians\n",
    "            buffer (int): buffer in meters\n",
    "\n",
    "        returns:\n",
    "            ee.Image\n",
    "        \"\"\"\n",
    "        # layover, where slope > radar viewing angle\n",
    "        layover = alpha_rRad.lt(theta_iRad).rename(\"layover\")\n",
    "\n",
    "        # shadow\n",
    "        shadow = alpha_rRad.gt(\n",
    "            ee.Image.constant(-1).multiply(ninetyRad.subtract(theta_iRad))\n",
    "        ).rename(\"shadow\")\n",
    "\n",
    "        # add buffer to layover and shadow\n",
    "        if buffer > 0:\n",
    "            layover = _erode(layover, buffer)\n",
    "            shadow = _erode(shadow, buffer)\n",
    "\n",
    "        # combine layover and shadow\n",
    "        no_data_mask = layover.And(shadow).rename(\"no_data_mask\")\n",
    "\n",
    "        return no_data_mask\n",
    "\n",
    "    # get the image geometry and projection\n",
    "    geom = image.geometry(scale)\n",
    "    proj = image.select(1).projection()\n",
    "    angle_band = image.select(\"angle\")\n",
    "\n",
    "    # image to convert angle to radians\n",
    "    to_radians = ee.Image.constant((math.pi / 180))\n",
    "    # create a 90 degree image in radians\n",
    "    ninetyRad = ee.Image.constant(90).multiply(to_radians)\n",
    "\n",
    "    # calculate the look direction\n",
    "    heading = (\n",
    "        ee.Terrain.aspect(image.select(\"angle\"))\n",
    "        .reduceRegion(ee.Reducer.mean(), geom, scale)\n",
    "        .get(\"aspect\")\n",
    "    )\n",
    "\n",
    "    # the numbering follows the article chapters\n",
    "    # 2.1.1 Radar geometry\n",
    "    theta_iRad = image.select(\"angle\").multiply(to_radians)\n",
    "    phi_iRad = ee.Image.constant(heading).multiply(to_radians)\n",
    "\n",
    "    # 2.1.2 Terrain geometry\n",
    "    alpha_sRad = (\n",
    "        ee.Terrain.slope(elevation)\n",
    "        .select(\"slope\")\n",
    "        .multiply(to_radians)\n",
    "        .setDefaultProjection(proj)\n",
    "    )\n",
    "\n",
    "    phi_sRad = (\n",
    "        ee.Terrain.aspect(elevation)\n",
    "        .select(\"aspect\")\n",
    "        .multiply(to_radians)\n",
    "        .setDefaultProjection(proj)\n",
    "    )\n",
    "\n",
    "    # 2.1.3 Model geometry\n",
    "    # reduce to 3 angle\n",
    "    phi_rRad = phi_iRad.subtract(phi_sRad)\n",
    "\n",
    "    # slope steepness in range (eq. 2)\n",
    "    alpha_rRad = (alpha_sRad.tan().multiply(phi_rRad.cos())).atan()\n",
    "\n",
    "    # slope steepness in azimuth (eq 3)\n",
    "    alpha_azRad = (alpha_sRad.tan().multiply(phi_rRad.sin())).atan()\n",
    "\n",
    "    # local incidence angle (eq. 4)\n",
    "    theta_liaRad = (\n",
    "        alpha_azRad.cos().multiply((theta_iRad.subtract(alpha_rRad)).cos())\n",
    "    ).acos()\n",
    "    theta_liaDeg = theta_liaRad.multiply(180 / math.pi)\n",
    "\n",
    "    # 2.2\n",
    "    # Gamma_nought\n",
    "    gamma0 = image.divide(theta_iRad.cos())\n",
    "\n",
    "    if model == \"volume\":\n",
    "        scf = _volumetric_model_SCF(theta_iRad, alpha_rRad)\n",
    "\n",
    "    elif model == \"surface\":\n",
    "        scf = _surface_model_SCF(theta_iRad, alpha_rRad, alpha_azRad)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"Defined model, {model}, has not been implemented. Options are 'volume' or 'surface'\"\n",
    "        )\n",
    "\n",
    "    # apply model for Gamm0_f\n",
    "    gamma0_flat = gamma0.divide(scf)\n",
    "\n",
    "    # calculate layover and shadow mask\n",
    "    masks = _masking(alpha_rRad, theta_iRad, buffer)\n",
    "\n",
    "    return (\n",
    "        gamma0_flat.updateMask(masks)\n",
    "        .addBands(angle_band)\n",
    "        .addBands(theta_liaDeg.rename(\"local_inc_angle\"))\n",
    "    )\n",
    "\n",
    "# define variables used within the slope_correction function\n",
    "elevation = ee.Image(\"NASA/NASADEM_HGT/001\").select(\"elevation\")\n",
    "model=\"volume\"\n",
    "buffer=100 # buffer areas of terrain shadow, in meters\n",
    "scale=1000 # processing scale for reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQFWVkZ2F1wd"
   },
   "outputs": [],
   "source": [
    "# define a function to apply the gamma map speckle filter algorithm\n",
    "def gamma_map(image):\n",
    "    \"\"\"Gamma Map speckle filtering algorithm.\n",
    "    Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ.\n",
    "\n",
    "    args:\n",
    "        img (ee.Image): Earth engine image object. Expects that imagery is a SAR image in power scale\n",
    "\n",
    "    returns:\n",
    "        ee.Image: filtered SAR power image using the Gamma Map algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    img_bands = image.bandNames()\n",
    "\n",
    "    # Square kernel, window should be odd (typically 3, 5 or 7)\n",
    "    weights = ee.List.repeat(ee.List.repeat(1, window), window)\n",
    "    midPt = (window // 2) + 1 if (window % 2) != 0 else window // 2\n",
    "\n",
    "    # ~~(window/2) does integer division in JavaScript\n",
    "    kernel = ee.Kernel.fixed(window, window, weights, midPt, midPt, False)\n",
    "\n",
    "    # Get mean and variance\n",
    "    mean = image.reduceNeighborhood(ee.Reducer.mean(), kernel)\n",
    "    variance = image.reduceNeighborhood(ee.Reducer.variance(), kernel)\n",
    "\n",
    "    # \"Pure speckle\" threshold\n",
    "    ci = variance.sqrt().divide(mean)  # square root of inverse of enl\n",
    "\n",
    "    # If ci <= cu, the kernel lies in a \"pure speckle\" area -> return simple mean\n",
    "    cu = 1.0 / math.sqrt(enl)\n",
    "\n",
    "    # If cu < ci < cmax the kernel lies in the low textured speckle area -> return the filtered value\n",
    "    cmax = math.sqrt(2.0) * cu\n",
    "\n",
    "    alpha = ee.Image(1.0 + cu * cu).divide(ci.multiply(ci).subtract(cu * cu))\n",
    "    b = alpha.subtract(enl + 1.0)\n",
    "    d = (\n",
    "        mean.multiply(mean)\n",
    "        .multiply(b)\n",
    "        .multiply(b)\n",
    "        .add(alpha.multiply(mean).multiply(image).multiply(4.0 * enl))\n",
    "    )\n",
    "    f = b.multiply(mean).add(d.sqrt()).divide(alpha.multiply(2.0))\n",
    "\n",
    "    caster = ee.Dictionary.fromLists(\n",
    "        img_bands, ee.List.repeat(\"float\", img_bands.length())\n",
    "    )\n",
    "    img1 = (\n",
    "        mean.updateMask(ci.lte(cu))\n",
    "        .rename(img_bands)\n",
    "        .cast(caster)\n",
    "    )\n",
    "    img2 = (\n",
    "        f.updateMask(ci.gt(cu)).updateMask(ci.lt(cmax))\n",
    "        .rename(img_bands)\n",
    "        .cast(caster)\n",
    "    )\n",
    "    img3 = image.updateMask(ci.gte(cmax)).rename(img_bands).cast(caster)\n",
    "\n",
    "    # If ci > cmax do not filter at all (i.e. we don't do anything, other then masking)\n",
    "    output = (\n",
    "        ee.ImageCollection([img1, img2, img3])\n",
    "        .reduce(ee.Reducer.firstNonNull())\n",
    "        .rename(img_bands)\n",
    "        .clip(image.geometry(1e3))\n",
    "    )\n",
    "\n",
    "    # Compose a 3 band image with the mean filtered \"pure speckle\", the \"low textured\" filtered and the unfiltered portions\n",
    "    return output\n",
    "    \n",
    "\n",
    "window=7 # filtering window size\n",
    "enl=4.9 # equivalent number of looks, for S1 enl ≈ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pp40UNJGZQC"
   },
   "outputs": [],
   "source": [
    "# this loads in a global vector file of countries\n",
    "# filter by country of interest\n",
    "region = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\").filter(\n",
    "    ee.Filter.eq(\"country_na\",\"Cambodia\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-LGvUFRFi4K"
   },
   "outputs": [],
   "source": [
    "# read in the power scale imagecollection\n",
    "s1_power_asc = (\n",
    "    ee.ImageCollection(\"COPERNICUS/S1_GRD_FLOAT\")\n",
    "    # filter for a flooding date\n",
    "    .filterDate('2019-09-11', '2019-09-12')\n",
    "    # filter for data in Cambodia\n",
    "    .filterBounds(region)\n",
    "    # Filter to get images with VV and VH dual polarization.\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
    "    # Filter to get images collected in interferometric wide swath mode.\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "    # filter orbit pass\n",
    "    .filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cjn15py5I-R3"
   },
   "outputs": [],
   "source": [
    "# apply RTC to imagery\n",
    "s1_rtc = s1_power_asc.map(slope_correction)\n",
    "# apply speckle filter\n",
    "s1_specfiltered = s1_rtc.map(gamma_map)\n",
    "# convert to dB units\n",
    "s1_db = s1_specfiltered.map(power_to_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBcTGhWnRgaZ"
   },
   "outputs": [],
   "source": [
    "s1_mosaic = s1_db.mosaic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3MwNVN6IHhN"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region,7)\n",
    "\n",
    "Map.addLayer(s1_mosaic.reproject(ee.Projection(\"EPSG:4326\").atScale(30)), {\"bands\":\"VV\", \"min\": -25, \"max\": 0}, 'dB image (reproject)')\n",
    "Map.addLayer(s1_mosaic, {\"bands\":\"VV\", \"min\": -25, \"max\": 0}, 'dB image')\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pWuO8T6K2K5"
   },
   "source": [
    "### Automated thresholding\n",
    "\n",
    "Now that we have our image we can begin our processing to extract surface water information using Otsu’s threshold. As mentioned before, the Otsu’s thresholding algorithm is histogram based, therefore we will need to create a histogram of values.  Otsu’s method only works for grayscale imagery (i.e. using one band) so we will use the VV band from S1. Also, Earth Engine allows us to easily calculate a histogram using a reducer. We will demostrate extracting a histogram for the whole image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08JfrvXfITVK"
   },
   "outputs": [],
   "source": [
    "# specify band to use for Otsu thresholding\n",
    "band = 'VV'\n",
    "\n",
    "# define a reducer to calculate a histogram of values\n",
    "histogram_reducer = ee.Reducer.histogram(255,0.1)\n",
    "\n",
    "# reduce all of the image values\n",
    "global_histogram = ee.Dictionary(\n",
    "  s1_mosaic.select(band).reduceRegion(\n",
    "    reducer = histogram_reducer,\n",
    "    geometry = region.geometry(maxError=1e3),\n",
    "    scale = 30,\n",
    "    maxPixels = 1e10,\n",
    "    bestEffort = True\n",
    "  ).get(band)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-BenoDiNwzJ"
   },
   "outputs": [],
   "source": [
    "# extract out the histogram buckets and counts per bucket\n",
    "bins = ee.List(global_histogram.get('bucketMeans')).getInfo()\n",
    "counts = ee.List(global_histogram.get('histogram')).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiZf5XhEN0Me"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(bins,counts)\n",
    "ax.set_xlabel(\"Backscatter [dB]\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlim(-30,10)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YithnpGqO9bC"
   },
   "source": [
    "As seen in the histogram, the data points are heavily skewed towards values around -10 to -5 dB. However, we can still see other small peaks of low backscatter values from -20 to -15 dB, these are the open water values.\n",
    "\n",
    "Next we will apply the Otsu’s thresholding algorithm on the histogram we just calculated. Earth Engine does not have a function for Otsu’s method, however, we can create a function that calculates the optimal threshold:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpHXqCnBO_2J"
   },
   "outputs": [],
   "source": [
    "def otsu(histogram):\n",
    "    \"\"\"Otsu's method threhsolding algorithm.\n",
    "    Computes single intensity threshold that separate histogram into two classes, foreground and background\n",
    "\n",
    "    args:\n",
    "        histogram (ee.Dictionary): computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\"\n",
    "\n",
    "    returns:\n",
    "        ee.Number: value of maximum inter-class intensity variance based on histogram\n",
    "    \"\"\"\n",
    "    counts = ee.Array(ee.Dictionary(histogram).get(\"histogram\"))\n",
    "    means = ee.Array(ee.Dictionary(histogram).get(\"bucketMeans\"))\n",
    "    size = means.length().get([0])\n",
    "    total = counts.reduce(ee.Reducer.sum(), [0]).get([0])\n",
    "    sums = means.multiply(counts).reduce(ee.Reducer.sum(), [0]).get([0])\n",
    "    mean = sums.divide(total)\n",
    "    indices = ee.List.sequence(1, size)\n",
    "    # Compute between sum of squares, where each mean partitions the data.\n",
    "\n",
    "    def bss_function(i):\n",
    "        aCounts = counts.slice(0, 0, i)\n",
    "        aCount = aCounts.reduce(ee.Reducer.sum(), [0]).get([0])\n",
    "        aMeans = means.slice(0, 0, i)\n",
    "        aMean = (\n",
    "            aMeans.multiply(aCounts)\n",
    "            .reduce(ee.Reducer.sum(), [0])\n",
    "            .get([0])\n",
    "            .divide(aCount)\n",
    "        )\n",
    "        bCount = total.subtract(aCount)\n",
    "        bMean = sums.subtract(aCount.multiply(aMean)).divide(bCount)\n",
    "        return aCount.multiply(aMean.subtract(mean).pow(2)).add(\n",
    "            bCount.multiply(bMean.subtract(mean).pow(2))\n",
    "        )\n",
    "\n",
    "    bss = indices.map(bss_function)\n",
    "    output = means.sort(bss).get([-1])\n",
    "    return ee.Number(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFC-PD9dN7Hx"
   },
   "outputs": [],
   "source": [
    "# apply Otsu algorithm to get threshold value\n",
    "global_threshold = otsu(global_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2wGkT9OQEdn"
   },
   "outputs": [],
   "source": [
    "global_t = global_threshold.getInfo()\n",
    "print(f\"Calculated threshold: {global_t:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5GBSw8WQMV9"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(bins,counts)\n",
    "ax.vlines(global_t,0,max(counts),color=\"r\")\n",
    "ax.set_xlabel(\"Backscatter [dB]\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlim(-30,10)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUs6oX1wQ1jP"
   },
   "source": [
    " We can now apply that threshold on the imagery and inspect how the extracted water looks compared to the original image. Here we apply the threshold and add the water image to the map:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7HRy2DbQ1Gs"
   },
   "outputs": [],
   "source": [
    "water_img = s1_mosaic.select(band).lt(global_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRLvd5GVQVis"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region,7)\n",
    "\n",
    "Map.addLayer(s1_mosaic.reproject(ee.Projection(\"EPSG:4326\").atScale(30)), {\"bands\":\"VV\", \"min\": -25, \"max\": 0}, 'dB image')\n",
    "Map.addLayer(water_img.selfMask(), {\"min\": 0, \"max\": 1, \"palette\":cmaps.get_palette(\"Blues\")}, 'Water image')\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyGZgb35S5Gw"
   },
   "source": [
    "From afar the results look promising, the blue areas shown overlap with the low backscatter (specular reflectance) that is representative of open water in C-band SAR imagery. However, upon closer inspection we can see that the extracted water overestimates in some areas that can be land areas.\n",
    "\n",
    "We see an overestimation as large local errors may be introduced when calculating a constant threshold for distinguishing water and land when using an image-wide histogram. It is due to this issue that algorithms have been developed to constrain the histogram sampling and have a more locally contextual threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-PohBLMT4qh"
   },
   "source": [
    "### Adaptive Thresholding\n",
    "\n",
    "As seen from the previous section, surface water usually constitutes only a small fraction of the overall land cover within an image. This makes it harder to apply threshold-based methods to extract water. The challenge is to establish a varying threshold that can be derived automatically. This section walks through an adaptive thresholding technique designed to overcome the challenges of using a global threshold.\n",
    "\n",
    "The method we will discuss was developed by [Donchyts et al. (2016)](https://doi.org/10.3390/rs8050386) and applied to the modified normalized difference water index (MNDWI) from Landsat 8 imagery. The algorithm finds edges within the image, then buffers the areas of identified edges, and uses the buffered area to sample a histogram for Otsu thresholding. This approach assumes that the edges detected are from water. The result is a bimodal histogram from the area around water edges that can be used to calculate a refined threshold. This approach was refined by [Markert et al. (2020)](https://doi.org/10.3390/rs12152469) where the main change was instead on calculating the edges on the raw values (from an index or otherwise), an initial segmentation threshold is provided to create a binary image to alleviate any edges being defined from other classes that are present in imagery (i.e., Urban Areas or Forests). Then the defined edges are filtered by length to omit small edges that can occur and skew the histogram sampling. This requires a few parameters that can be tuned, namely the initial threshold, edge length, and buffer size. Here we define a few of those parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knpoivVzSAID"
   },
   "outputs": [],
   "source": [
    "# define paramters for the adaptive thresholding \n",
    "initial_threshold = -16 # initial estimate of water/no-water for estimating the edges\n",
    "connected_pixels = 100 # number of connected pixels to use for length calculation\n",
    "edge_length = 20 # length of edges to be considered water edges\n",
    "edge_buffer = 300 # buffer in meters to apply to edges\n",
    "canny_threshold = 1 # threshold for canny edge detection\n",
    "canny_sigma = 1 # sigma value for gaussian filter in canny edge detection\n",
    "canny_lt = 0.05 # lower threshold for canny detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1QZeMlwU3hZ"
   },
   "source": [
    "With these parameters defined, we can begin the process of constraining the histogram sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sn_mAB78Ux6h"
   },
   "outputs": [],
   "source": [
    "# get preliminary water\n",
    "binary = s1_mosaic.select(band).lt(initial_threshold).rename('binary');\n",
    "\n",
    "# get projection information to convert buffer size to npixels\n",
    "image_proj = s1_power_asc.first().select(band).projection()\n",
    "\n",
    "# get canny edges\n",
    "canny = ee.Algorithms.CannyEdgeDetector(binary, canny_threshold, canny_sigma)\n",
    "# process canny edges\n",
    "# get the edges and length of edges\n",
    "connected  = canny.updateMask(canny).lt(canny_lt).connectedPixelCount(connected_pixels, True)\n",
    "# mask short edges that can be noise\n",
    "edges = connected.gte(edge_length)\n",
    "# calculate the buffer in pixel size\n",
    "edge_buffer_pixel = ee.Number(edge_buffer).divide(image_proj.nominalScale())\n",
    "# buffer the edges using an efficient dilation operation\n",
    "buffered_edges = edges.fastDistanceTransform().lt(edge_buffer_pixel)\n",
    "\n",
    "# mask areas not within buffer \n",
    "edge_image = s1_mosaic.select(band).updateMask(buffered_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGIOt37PapXM"
   },
   "source": [
    "Now that we have the edge information and data to sample processed, we can visually inspect what the algorithm is doing. Here we will display the edges calculated as well as the buffered edges to highlight which data is being sampled:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2kAG9OSVwpC"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region,7)\n",
    "\n",
    "Map.addLayer(s1_mosaic.reproject(ee.Projection(\"EPSG:4326\").atScale(30)), {\"bands\":\"VV\", \"min\": -25, \"max\": 0}, 'dB image')\n",
    "Map.addLayer(edges,{\"palette\":\"red\"},\"Detected water edges\")\n",
    "Map.addLayer(buffered_edges,{\"palette\":\"gray,yellow\",\"min\":0, \"max\":1,\"opacity\":0.5},\"Buffered water edges\")\n",
    "Map.addLayer(edge_image, {\"bands\":\"VV\", \"min\": -25, \"max\": 0}, 'dB image edges')\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3f6jENuaqo0"
   },
   "source": [
    "From this point we have our regions that we want to sample that are more representative of a bimodal histogram and we have masked out areas that we don’t want to sample. Now we can calculate the histogram as before and make a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV3e4l6uV-o9"
   },
   "outputs": [],
   "source": [
    "# reduce all of the image values\n",
    "local_histogram = ee.Dictionary(\n",
    "  edge_image.select(band).reduceRegion(\n",
    "    reducer = histogram_reducer,\n",
    "    geometry = region.geometry(1e3),\n",
    "    scale = 30,\n",
    "    maxPixels = 1e10,\n",
    "    bestEffort = True\n",
    "  ).get(band)\n",
    ")\n",
    "\n",
    "# apply Otsu algorithm to get threshold value\n",
    "local_threshold = otsu(local_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "gSgYAo2ZbAde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated threshold: -14.6020\n"
     ]
    }
   ],
   "source": [
    "# extract out the histogram buckets and counts per bucket\n",
    "bins = ee.List(local_histogram.get('bucketMeans')).getInfo()\n",
    "counts = ee.List(local_histogram.get('histogram')).getInfo()\n",
    "local_t = local_threshold.getInfo()\n",
    "\n",
    "print(f\"Calculated threshold: {local_t:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBo8Um1xbJAt"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(bins,counts)\n",
    "ax.vlines(local_t,0,max(counts),color=\"r\")\n",
    "ax.set_xlabel(\"Backscatter [dB]\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlim(-30,10)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOLpDEGYbSPD"
   },
   "source": [
    "We can see from the histogram that we have a better distinction of water/land values which meet our assumption of Otsu’s thresholding of two classes. This allows the algorithm to more accurately calculate the threshold for water. The last thing left to do is apply the calculated adaptive threshold on the imagery and add it to the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJGfXAK3bOCs"
   },
   "outputs": [],
   "source": [
    "water_img = s1_mosaic.select(band).lt(local_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc2BPAUUbdVK"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region,7)\n",
    "\n",
    "Map.addLayer(s1_mosaic.reproject(ee.Projection(\"EPSG:4326\").atScale(30)), {\"bands\":\"VV\", \"min\": -25, \"max\": 0}, 'dB image')\n",
    "Map.addLayer(water_img.selfMask(), {\"min\": 0, \"max\": 1, \"palette\":cmaps.get_palette(\"Blues\")}, 'Water image')\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETriYS5tdbg3"
   },
   "source": [
    "Now that we have a surface water map and we are moderately confident it represents the actual surface water for that day, we can begin to identify flooded areas by differencing our resulting map with historical information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "771rCppCdi9h"
   },
   "source": [
    "## Extracting flood area\n",
    "\n",
    "Up to this point we have been mapping surface water, surface water is a term that includes permanent and seasonal water for what was observed by the sensor. What we need to do now is to identify areas from our image that are considered permanent water. There are typically two approaches to map flooded areas with a thematic surface water map: 1) comparing pre- and post-event images to estimate changes or 2) compare extracted surface water with historically observed permanent water.\n",
    "\n",
    "To achieve the goal of flood mapping, we will use the historical JRC Global Surface Water dataset ([Pekel et al., 2016](https://doi.org/10.1038/nature20584)) to define permanent water and then find the difference to extract flooded areas. We already have our surface water map post-event, now we need to define the JRC data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxOtyXqHc0UT"
   },
   "outputs": [],
   "source": [
    "# get the previous 5 years of permanent water\n",
    "# get the JRC historical yearly dataset\n",
    "jrc = (\n",
    "    ee.ImageCollection(\"JRC/GSW1_2/YearlyHistory\") \n",
    "    .filterDate(\"1985-01-01\",\"2019-09-12\") # filter for historical data up to date of interest\n",
    "    .limit(5, \"system:time_start\", False) # grab the 5 latest images/years\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK0QRsjjeIzm"
   },
   "source": [
    "This data is a yearly classification of permanent and seasonal water, so now what we need to do is reclassify the imagery to just permanent water:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qg-ieLJ-eEco"
   },
   "outputs": [],
   "source": [
    "# define function to extract out the water class\n",
    "def permanent_water_reclassify(image):\n",
    "    return image.select(\"waterClass\").eq(3)\n",
    "\n",
    "permanent_water = (\n",
    "    jrc\n",
    "    .map(permanent_water_reclassify) # apply reclassification\n",
    "    .sum() # reduce collection to information on if a pixel has been classified as permanent water in the past 5 years\n",
    "    .unmask(0) # make sure we have a value everywhere\n",
    "    .gt(0) # get a binary image of 1 if permanent water in the past 5 years, otherwise 0\n",
    "    .updateMask(water_img.mask()) # mask for only the water image we just calculated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQE-094feq7z"
   },
   "outputs": [],
   "source": [
    "# find areas where there is not permanent water and water from observation\n",
    "flood_img = permanent_water.Not().And(water_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSbYei4JezGD"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(region,7)\n",
    "\n",
    "Map.addLayer(s1_mosaic.reproject(ee.Projection(\"EPSG:4326\").atScale(30)), {\"bands\":\"VV\", \"min\": -25, \"max\": 0}, 'dB image')\n",
    "Map.addLayer(water_img.selfMask(), {\"min\": 0, \"max\": 1, \"palette\":cmaps.get_palette(\"Blues\")}, 'Observed Surface Water')\n",
    "# add the permanent water layer to the map\n",
    "Map.addLayer(permanent_water.selfMask(), {\"palette\": \"royalblue\"}, \"JRC permanent water\");\n",
    "# add flood image to map\n",
    "Map.addLayer(flood_img.selfMask(),{\"palette\":\"firebrick\"},\"Flood areas\");\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i53YYKXXf5d_"
   },
   "source": [
    "There are nuances associated with comparing optically derived water information (like from JRC) with SAR water maps. For example, any surface that is large enough and smooth can “look” like water in SAR imagery because of specular scattering and can be wrongly classified as floods. Examples of this are airports, exposed channel beds, and highways. Therefore, comparing pre- and post-event imagery from the same sensor is best, however, it is challenging to define events in seasonal flooding (such as this case) making a pre- and post-event comparison a little more complicated.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPmuv/dguPGI1o5djqEhaPO",
   "collapsed_sections": [],
   "name": "Lab 9 - Remote sensing of surface water / floods.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
