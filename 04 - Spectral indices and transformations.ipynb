{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5Bz3yki7hx4"
   },
   "source": [
    "# Lab 4: Radiometric calibration, spectral indices, and transformations\n",
    "\n",
    "**Purpose:** The purpose of this lab is to walk through radiometric calibration of Landsat data as well as give you a tour of spectral indices that can be used to enhance phenomena of interest in remotely sensed images.  You will be introduced to methods for creating vegetation, water, snow, bare and burned area indices.  You will explore spectral unmixing.  At the completion of the lab, you will be able to implement spectral indices and transforms to accentuate the information of interest in your study area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TkiHmgi8CRq"
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "from geemap import colormaps as cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNpAABRs8FEZ"
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f95ocyLmCnzs"
   },
   "source": [
    "## Radiometric Calibration - Landsat\n",
    "\n",
    "We have used Landsat data with a couple of different units (Digital Numbers, Top-of-atmosphere reflectance, and surface reflectance), however, the imagery is typically stored as DNs.  The example will walk though the process to convert DN values into top-of-atmophere reflectance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftiInnGIDtuM"
   },
   "source": [
    "### Top-of-atmopshere Radiance\n",
    "\n",
    "To convert DN values into at-sensor radiance units in $Watts \\cdot m^{-2} \\cdot sr^{-1} \\cdot \\mu m^{-1}$, use a linear equation of the form:\n",
    "\n",
    "$L_\\lambda = a_\\lambda \\cdot DN_\\lambda + b_\\lambda$\n",
    "\n",
    "Note that every term is indexed by lamda ($\\lambda$, the symbol for wavelength) because the coefficients are different in each band.  See [Chander et al. (2009)](https://doi.org/10.1016/j.rse.2009.01.007) for details on this linear transformation between DN and radiance.\n",
    "\n",
    "**Note:** At-sensor and top-of-atmosphere are sometimes used interchagebly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0h3C8zywDt1X"
   },
   "outputs": [],
   "source": [
    "# load in a Landsat image based on \n",
    "image_id = \"LANDSAT/LC08/C02/T1/LC08_044034_20141012\"\n",
    "\n",
    "# select only the first 7 bands in the image which \n",
    "# are the visible to middle infrared bands\n",
    "image = ee.Image(image_id).select(\"B[1-7]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDb4lRa7OxBX"
   },
   "outputs": [],
   "source": [
    "# check the band names\n",
    "image.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSMjZKr4qN34"
   },
   "outputs": [],
   "source": [
    "image.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1zLJ7SfKiKk"
   },
   "outputs": [],
   "source": [
    "# define lists of the property names that represent the \n",
    "# scale and offset for calculating radiance\n",
    "rad_add_names = [f\"RADIANCE_ADD_BAND_{i}\" for i in range(1,8)]\n",
    "rad_mult_names = [f\"RADIANCE_MULT_BAND_{i}\" for i in range(1,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKuAmXzWEFNZ"
   },
   "outputs": [],
   "source": [
    "# extract out the scale and offset metadata values for the bands\n",
    "rad_add_vals = image.toDictionary(rad_add_names)\n",
    "rad_mult_vals = image.toDictionary(rad_mult_names)\n",
    "\n",
    "# convert the values to an 7-band image\n",
    "rad_add_img = rad_add_vals.toImage()\n",
    "rad_mult_img = rad_mult_vals.toImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wERxOviWFEEt"
   },
   "outputs": [],
   "source": [
    "# apply the scale and offset factors to \n",
    "# convert DN to TOA radiance\n",
    "radiance = image.multiply(rad_mult_img).add(rad_add_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kG8KKC9qFIPK"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B4\",\"B3\",\"B2\"], \"min\": 5000, \"max\": 15000, \"gamma\": 1.3}, 'DN values');\n",
    "Map.addLayer(radiance,{\"bands\":\"B4,B3,B2\", \"min\":5, \"max\":100, \"gamma\":1.3}, \"TOA Radiance\")\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo-enH2JLD5u"
   },
   "source": [
    "### Top-of-atmopshere Reflectance\n",
    "\n",
    "Now that we have TOA Radiance we would like to convert these to reflectance values. To do so, we can apply to \n",
    "\n",
    "$\\rho_\\lambda = \\frac{\\pi \\cdot L_\\lambda \\cdot d^2}{ESUN_\\lambda \\cdot cos\\theta_{sz}}$\n",
    "\n",
    "There are a few more things we would need to extract to caculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sR_AjuUnFcdj"
   },
   "outputs": [],
   "source": [
    "# create and image for pi\n",
    "pi = ee.Image(math.pi)\n",
    "\n",
    "# extract out the earth sun distance and create an image\n",
    "d = image.metadata(\"EARTH_SUN_DISTANCE\")\n",
    "\n",
    "# extract out the solar elevation angle and create an image\n",
    "# convert from degrees to radians\n",
    "se = image.metadata(\"SUN_ELEVATION\").multiply(pi.divide(180))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVFGSW_oWDqe"
   },
   "source": [
    "USGS and NASA decided not to publish ESUN values because they are not required for conversion to reflectance any more but we can still calculate them from the radiance and reflectance scale factors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHUSp9IbTZOJ"
   },
   "outputs": [],
   "source": [
    "# create a list of \n",
    "ref_mult_names = [f\"REFLECTANCE_MULT_BAND_{i}\" for i in range(1,8)]\n",
    "ref_mult_vals = image.toDictionary(ref_mult_names)\n",
    "ref_mult_img = ref_mult_vals.toImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQAoPvC4XNWF"
   },
   "outputs": [],
   "source": [
    "esun = ee.Image().expression(\"pi * (d**2) * (radb / refb)\",{\n",
    "    \"pi\": pi,\n",
    "    \"d\": d,\n",
    "    \"radb\": rad_mult_img,\n",
    "    \"refb\": ref_mult_img\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXp907tbSr2h"
   },
   "outputs": [],
   "source": [
    "reflectance = ee.Image().expression(\"(pi*rad*(d**2))/(esun * sin(se))\",{\n",
    "    \"pi\": pi,\n",
    "    \"rad\": radiance,\n",
    "    \"d\": d,\n",
    "    \"esun\": esun,\n",
    "    \"se\": se\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egU5bt4-TEo0"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B4\",\"B3\",\"B2\"], \"min\": 5000, \"max\": 15000, \"gamma\": 1.3}, 'DN values');\n",
    "Map.addLayer(radiance,{\"bands\":\"B4,B3,B2\", \"min\":5, \"max\":100, \"gamma\":1.3}, \"TOA Radiance\")\n",
    "Map.addLayer(reflectance,{\"bands\":\"B4,B3,B2\", \"min\":0, \"max\":0.33, \"gamma\":1.3}, \"TOA Reflectance\")\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yj9i5ywqYhvg"
   },
   "source": [
    "### Surface reflectance\n",
    "\n",
    "To calculate surface reflectance requires a much more complex process. We will not go through calculating surface reflectance but rather import the data directly to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e_V-1CwYg9Z"
   },
   "outputs": [],
   "source": [
    "# read in surface reflectance image\n",
    "# rescale to surface reflectance values\n",
    "# select bands 1-7 \n",
    "sr = (\n",
    "    ee.Image(\"LANDSAT/LC08/C02/T1_L2/LC08_044034_20141012\")\n",
    "    .multiply(2.75e-05).add(-0.2)\n",
    "    .select(\"SR_B[1-7]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBRxEHXSaE_G"
   },
   "source": [
    "### Spectra from different units\n",
    "\n",
    "The conversion from top-of-atmosphere radiance to surface reflectance is not to just make pretty pictures, we are adjusting the physical values to represent what we would measure on the ground. The results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_HDZv_Jc8wa"
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7-nRMQuaP4A"
   },
   "outputs": [],
   "source": [
    "water = ee.Geometry.Point(-122.6787, 37.5181)\n",
    "forest = ee.Geometry.Point(-122.6715, 37.9494)\n",
    "urban = ee.Geometry.Point(-122.41712, 37.75641)\n",
    "ag = ee.Geometry.Point(-121.50267, 37.85451)\n",
    "\n",
    "pts = ee.FeatureCollection([water,forest,urban,ag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5T8haVjgJ6H"
   },
   "outputs": [],
   "source": [
    "def plot_spectra(img, units):\n",
    "    spectra_dict = img.reduceRegions(pts, ee.Reducer.mean(), 30).getInfo()\n",
    "\n",
    "    f,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    for i,f in enumerate(spectra_dict[\"features\"]):\n",
    "        spectra = list(f[\"properties\"].values())\n",
    "        ax.plot(wavelengths, spectra, color=colors[i], marker=\"o\",label=feature_names[i],lw=1.5)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_xlabel(\"Wavelength [$\\mu m$]\")\n",
    "    ax.set_ylabel(units)\n",
    "    return\n",
    "\n",
    "colors = [\"C0\",\"C2\",\"C1\",\"C4\"]\n",
    "wavelengths = [0.44, 0.48,0.56,0.655,0.865,1.61,2.20]\n",
    "feature_names = [\"Water\",\"Forest\", \"Urban\", \"Agriculture\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "na7WimWodHN_"
   },
   "outputs": [],
   "source": [
    "plot_spectra(radiance,\"Radiance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvWAbNh0ftqg"
   },
   "outputs": [],
   "source": [
    "plot_spectra(reflectance,\"TOA Reflectance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a73j20D1f2XA"
   },
   "outputs": [],
   "source": [
    "plot_spectra(sr,\"Surface Reflectance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6uXVcEXixPz"
   },
   "source": [
    "Notice how the spectral curves of the different land surface features change with each processed image. What do these changes mean? Think of the physical process we are compensating for at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZ0iMafGjGam"
   },
   "source": [
    "## Spectral indices\n",
    "\n",
    "Now that we have a good understanding of why and how to create surface reflectance data, we will explore what to do with it. Spectral indices are based on the fact that reflectance spectra of different land covers are different (as seen from the plots above).  The indices are designed to exploit these differences to accentuate particular land cover types. \n",
    "\n",
    "From thea above plots we can observe that the land covers are separable at one or more wavelengths.  Note, in particular, that vegetation curves have relatively high reflectance in the NIR range, where radiant energy is scattered by cell walls ([Bowker et al. 1985](http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19850022138.pdf)).  Also note that vegetation has low reflectance in the red range, where radiant energy is [absorbed by chlorophyll](https://en.wikipedia.org/wiki/Chlorophyll#/media/File:Chlorophyll_ab_spectra-en.svg).  These observations motivate the formulation of vegetation indices, such as the Normalized Difference Vegetation Index (NDVI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWKD5NA_mZnZ"
   },
   "outputs": [],
   "source": [
    "# before beginning set out surface reflectance image to the `image` variable\n",
    "# for readability\n",
    "image = sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMrdkG29j3yn"
   },
   "source": [
    "### NDVI\n",
    "\n",
    "The Normalized Difference Vegetation Index (NDVI) has a [long history](https://en.wikipedia.org/wiki/Normalized_Difference_Vegetation_Index) in remote sensing.  The typical formulation is\n",
    "\n",
    "$NDVI = \\frac{(NIR - red)}{(NIR + red)}$\n",
    "\n",
    "Where NIR and red refer to reflectance, radiance or DN at the respective wavelength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMy7iX6FmJvY"
   },
   "source": [
    "We are going to use the built-in EE function `.normalizedDifference()` to calculate NDVI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1en-PPljF6d"
   },
   "outputs": [],
   "source": [
    "ndvi = image.normalizedDifference([\"SR_B5\",\"SR_B4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6VVotXZmuVz"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"SR_B4\",\"SR_B3\",\"SR_B2\"], \"min\": 0, \"max\": 0.33, \"gamma\": 1.3}, 'Surface Reflectance');\n",
    "Map.addLayer(ndvi,{\"min\":0,\"max\":1, \"palette\":cmaps.get_palette(\"Greens\")}, \"NDVI\")\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSP61VJZorbE"
   },
   "source": [
    "Do you notice anything missing from the image? Why would there be missing pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4hUML3voqGQ"
   },
   "outputs": [],
   "source": [
    "# create our own normalized difference function to prevent missing pixels\n",
    "def normalized_difference(img,bands):\n",
    "    b1 = img.select(bands[0])\n",
    "    b2 = img.select(bands[1])\n",
    "\n",
    "    return b1.subtract(b2).divide(b1.add(b2)).rename(\"nd\").clamp(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGUUicJHnY73"
   },
   "source": [
    "### NDWI\n",
    "\n",
    "The Normalized Difference Water Index (NDWI) was developed by [Gao (1996)](http://www.sciencedirect.com/science/article/pii/S0034425796000673) as an index of vegetation water content:\n",
    "\n",
    "$NDWI = \\frac{(NIR - SWIR)}{(NIR + SWIR)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IdcI-CQnm9l"
   },
   "outputs": [],
   "source": [
    "ndwi = normalized_difference(image, [\"SR_B5\",\"SR_B6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFEjojhbnre3"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"SR_B4\",\"SR_B3\",\"SR_B2\"], \"min\": 0, \"max\": 0.33, \"gamma\": 1.3}, 'Surface Reflectance');\n",
    "Map.addLayer(ndwi,{\"min\":-1,\"max\":1, \"palette\":cmaps.get_palette(\"Blues\")}, \"NDWI\")\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR68HULYn4cT"
   },
   "source": [
    "### MNDWI\n",
    "\n",
    "The modified Normalized Difference Water Index (mNDWI) was developed by [Xu 2006](https://www.tandfonline.com/doi/abs/10.1080/01431160600589179) to better distigush open water as opposed to vegetation water content which is what NDWI highlights. It takes the form of the following:\n",
    "\n",
    "$MNDWI = \\frac{(green - SWIR1)}{(green + SWIR1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HrEuV5vn3oL"
   },
   "outputs": [],
   "source": [
    "mndwi = normalized_difference(image,[\"SR_B3\",\"SR_B6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxpqHxMboevT"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"SR_B4\",\"SR_B3\",\"SR_B2\"], \"min\": 0, \"max\": 0.33, \"gamma\": 1.3}, 'Surface Reflectance');\n",
    "Map.addLayer(mndwi,{\"min\":-1,\"max\":1, \"palette\":cmaps.get_palette(\"Blues\")}, \"mNDWI\")\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTl0OSHJqCCP"
   },
   "source": [
    "It should be noted that there is *another* normalized difference water index developed in 1996 by [McFeeters (1996)](http://www.tandfonline.com/doi/abs/10.1080/01431169608948714#.VkThFHyrTlM) called the Normalized Difference Water Body Index (NDWBI) which uses the green and NIR bands. Be aware that there are multiple indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh_TmSTgqid8"
   },
   "source": [
    "### NDBI\n",
    "\n",
    "The Normalized Difference Bare Index (NDBI) was developed by [Zha et al. (2003)](http://www.tandfonline.com/doi/abs/10.1080/01431160304987) to aid in the differentiation of urban areas:\n",
    "\n",
    "$NDBI = \\frac{SWIR - NIR}{SWIR + NIR}$\n",
    "\n",
    "**Note:** Note that NDBI is the negative of NDWI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o50kh26Wq1SC"
   },
   "outputs": [],
   "source": [
    "ndbi = normalized_difference(image, [\"SR_B6\",\"SR_B5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0azRXJ_q8th"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"SR_B4\",\"SR_B3\",\"SR_B2\"], \"min\": 0, \"max\": 0.33, \"gamma\": 1.3}, 'Surface Reflectance');\n",
    "Map.addLayer(ndbi,{\"min\":-1,\"max\":0.5, \"palette\":cmaps.get_palette(\"Oranges\")}, \"NDBI\")\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B2GsM2NtNF8"
   },
   "source": [
    "### BAI\n",
    "\n",
    "The Burned Area Index (BAI) was developed by [Chuvieco et al. (2002)](http://www.tandfonline.com/doi/abs/10.1080/01431160210153129) to assist in the delineation of burn scars and assessment of burn severity.  It is based on the spectral distance to charcoal reflectance.  To examine burn indices, load an image from 2013 showing the [Rim fire](https://en.wikipedia.org/wiki/Rim_Fire) in the Sierra Nevadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T18nrHTJrtPg"
   },
   "outputs": [],
   "source": [
    "lc8_sr = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cSILLGHrcxu"
   },
   "outputs": [],
   "source": [
    "burn_image = ee.Image(\n",
    "    lc8_sr\n",
    "    .filterBounds(ee.Geometry.Point(-120.083, 37.850))\n",
    "    .filterDate('2013-08-17', '2013-09-27')\n",
    "    .sort('CLOUD_COVER')\n",
    "    .first()\n",
    "    .multiply(2.75e-05).add(-0.2) # rescale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOj4vVxfr0es"
   },
   "outputs": [],
   "source": [
    " bai = burn_image.expression(\n",
    "    '1.0 / ((0.1 - RED)**2 + (0.06 - NIR)**2)', {\n",
    "      'NIR': burn_image.select('SR_B5'),\n",
    "      'RED': burn_image.select('SR_B4'),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mvvK25tr7Nv"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(burn_image, 10)\n",
    "\n",
    "Map.addLayer(burn_image, {\"bands\": [\"SR_B4\",\"SR_B3\",\"SR_B2\"], \"min\": 0, \"max\": 0.33, \"gamma\": 1.3}, 'Surface Reflectance');\n",
    "Map.addLayer(bai,{\"min\":0,\"max\":400, \"palette\":cmaps.get_palette(\"Oranges\")}, \"BAI\", False)\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EajHBhostbWg"
   },
   "source": [
    "### NDSI\n",
    "\n",
    "The Normalized Difference Snow Index (NDSI) was designed to estimate the amount of a pixel covered in snow ([Riggs et al. 1994](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=399618&tag=1)):\n",
    "\n",
    "$NDSI = \\frac{green - SWIR}{green + SWIR}$\n",
    "\n",
    "Do you notice anything interesting about this index compared to the others?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWP12XGutY2e"
   },
   "outputs": [],
   "source": [
    "snow_image = ee.Image(\n",
    "    lc8_sr\n",
    "    .filterBounds(ee.Geometry.Point(-120.0421, 39.1002))\n",
    "    .filterDate('2013-11-01', '2014-05-01')\n",
    "    .sort('CLOUD_COVER')\n",
    "    .first()\n",
    "    .multiply(2.75e-05).add(-0.2) # rescale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WwaQpwKSt19C"
   },
   "outputs": [],
   "source": [
    "ndsi = normalized_difference(snow_image,[\"SR_B3\",\"SR_B6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLUgB7i-t9l5"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(snow_image, 10)\n",
    "\n",
    "Map.addLayer(snow_image, {\"bands\": [\"SR_B4\",\"SR_B3\",\"SR_B2\"], \"min\": 0, \"max\": 0.33, \"gamma\": 1.3}, 'Surface Reflectance');\n",
    "Map.addLayer(ndsi,{\"min\":-1,\"max\":1, \"palette\":cmaps.get_palette(\"cubehelix\")}, \"NDSI\")\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8G6mojxukhm"
   },
   "source": [
    "## Spectral unmixing\n",
    "\n",
    "The [linear spectral mixing model](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=974727&tag=1) is based on the assumption that each pixel is a mixture of \"pure\" spectra.  The pure spectra, called endmembers, are from land cover classes such as water, bare land, vegetation.  The goal is to solve the following equation for f, the Px1 vector of endmember fractions in the pixel: \n",
    "\n",
    "$Sf = p$\n",
    "\n",
    "where **S** is a *BxP* matrix in which the columns are *P* pure endmember spectra (known) and **p** is the *Bx1* pixel vector when there are B bands (known).  In this example, B=6.\n",
    "\n",
    "Consider the following spectral curves:\n",
    "\n",
    "![Mixed Spectra](https://imgur.com/oCdDPrW.png)\n",
    "\n",
    "In this case Water = 50% of the pixel, Dense Veg. = 40% of the pixel, and Sparse Veg. = 10% of pixel. By compining the weights at each band we get the spectral curve in black. The black spectral curve is what the satellite observes and we can estimate the percent coverage of each land cover type based on what we expect from a \"pure pixel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baCG3CeYu8D9"
   },
   "outputs": [],
   "source": [
    "unmix_image = image.select(['SR_B[2-7]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toiwFCJMvCK6"
   },
   "source": [
    "The first step is to get the endmember spectra.  There are algorithms available to estimate the \"pure\" pixel spectra (such as the Dynamic Nearest Neighbor Search algorithm). However, for this case we we hard code our endmember spectra:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRe8QoXyvC-W"
   },
   "outputs": [],
   "source": [
    "# define expected spectra for \n",
    "water = [0.032,0.055,0.037,0.001,0.001,0.002]\n",
    "urban = [0.18,0.24,0.26,0.265,0.315,0.315]\n",
    "veg = [0.01,0.019,0.015,0.168,0.069,0.027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPzzg_fH5eS2"
   },
   "outputs": [],
   "source": [
    "# apply the unmixing and force the results to be 0-1\n",
    "fractions = unmix_image.unmix([urban,veg,water],sumToOne=True,nonNegative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEd1AUnI5jOd"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"SR_B4\",\"SR_B3\",\"SR_B2\"], \"min\": 0, \"max\": 0.33, \"gamma\": 1.3}, 'Surface Reflectance');\n",
    "Map.addLayer(fractions,{\"min\":0,\"max\":1,}, \"Unmixed Fractions\")\n",
    "\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONcUpoC12ruAehg3emX2jN",
   "collapsed_sections": [
    "zZ0iMafGjGam",
    "R8G6mojxukhm"
   ],
   "name": "Lab 4 - Spectral indices and transformations.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
