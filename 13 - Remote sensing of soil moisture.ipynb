{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ighbboD6dbzZ"
   },
   "source": [
    "# Lab 13: Remote sensing of soil moisture\n",
    "\n",
    "**Purpose:** In this chapter, you will work with a soil moisture data set on Earth Engine and combine multiple dataset together in attempt to predict higher resolution soil moisture values. You will work on managing multiple dataset, applying joins, and a machine learning work flow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMXXkqlndsIg"
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U92tLCA_dsFL"
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import math\n",
    "import geemap\n",
    "import pandas as pd\n",
    "from geemap import colormaps as cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLrc4hxMdsAb"
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjXQeoo10CmR"
   },
   "source": [
    "## Background\n",
    "\n",
    "Soil moisture is an important variable in the hydrologic system which controls the exchange of water, energy, and carbon fluxes between the land surface and the atmosphere. Traditionally, soil moisture is retrieved from microwave remote sensing data but these data are typically not suitable for regional hydrological and agricultural applications such as irrigation management and flood predictions due to their coarse spatial resolution ([Peng et al., 2017](https://doi.org/10.1002/2016RG000543)).\n",
    "\n",
    "Many methods have been developed to downscale the coarse. Some of these methods rely on coincident observations and physical models of how soil moisture interacts with what we can observe whereas other methods are more statistical in nature ([Mishra et al., 2018](https://doi.org/10.1016/j.jag.2018.02.005)). For this lab we will implement a pure statistical \"downscaling\" approach to estimate soil moisture at higher spatial resolution using other datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbYH2CKveqb3"
   },
   "source": [
    "## Soil moisture downscaling using ML\n",
    "\n",
    "As mentioned above, we will be using a statistical approach to estimate soil moisture at higher spatial resolution. The approach will rely on multipl disparate datasets that may or may not be collected at different times. The bulk of this notebook will focus on how one manages and uses these different datasets together in an efficient manner for machine learning.\n",
    "\n",
    "For this methodology, we will test using NDVI, Land Surface Temperature, Precipitation, and a soil classification to estimate soil moisture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfTdahAmausq"
   },
   "source": [
    "### Data gathering\n",
    "\n",
    "First off, we need data. Here we will load in the dataset that we will use for the ML estimation of soil moisture and apply the neccesary pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ2Epcyd0ljt"
   },
   "outputs": [],
   "source": [
    "# define our start/end time to filter the data collections\n",
    "start_time = \"2016-01-01\"\n",
    "end_time = \"2022-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ev0DeBN0W22"
   },
   "outputs": [],
   "source": [
    "# define a function to do the bit shifting for us fo QA processing\n",
    "def extract_bits(image, start, end=None, new_name=None):\n",
    "    \"\"\"Function to convert qa bits to binary flag image\n",
    "\n",
    "    args:\n",
    "        image (ee.Image): qa image to extract bit from\n",
    "        start (int): starting bit for flag\n",
    "        end (int | None, optional): ending bit for flag, if None then will only use start bit. default = None\n",
    "        new_name (str | None, optional): output name of resulting image, if None name will be {start}Bits. default = None\n",
    "\n",
    "    returns:\n",
    "        ee.Image: image with extract bits\n",
    "    \"\"\"\n",
    "\n",
    "    newname = new_name if new_name is not None else f\"{start}_bits\"\n",
    "\n",
    "    if (start == end) or (end is None):\n",
    "        # perform a bit shift with bitwiseAnd\n",
    "        return image.select([0], [newname]).bitwiseAnd(1 << start)\n",
    "    else:\n",
    "        # Compute the bits we need to extract.\n",
    "        pattern = 0\n",
    "        for i in range(start, end):\n",
    "            pattern += int(math.pow(2, i))\n",
    "\n",
    "        # Return a single band image of the extracted QA bits, giving the band\n",
    "        # a new name.\n",
    "        return image.select([0], [newname]).bitwiseAnd(pattern).rightShift(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhJTHGXH0bJe"
   },
   "outputs": [],
   "source": [
    "# function to preprocess the modis LST data\n",
    "def lst_preprocess(image):\n",
    "    # get QA band\n",
    "    qa_band = image.select(\"QC_Day\")\n",
    "\n",
    "    # extract QA bits\n",
    "    mask = extract_bits(qa_band, start=2, end=3).eq(0)\n",
    "\n",
    "    # apply mask and rescale to Celcius\n",
    "    return image.multiply(0.02).subtract(273.15).updateMask(mask).copyProperties(image,[\"system:time_start\",\"system:time_end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWH9PUcD3kha"
   },
   "outputs": [],
   "source": [
    "# function to preprocess the modis LST data\n",
    "def sr_preprocess(image):\n",
    "    # get QA band\n",
    "    qa_band = image.select(\"QC_250m\")\n",
    "\n",
    "    # extract QA bits\n",
    "    mask = extract_bits(qa_band, start=0, end=1).eq(0)\n",
    "\n",
    "    # calculate NDVI\n",
    "    ndvi = image.normalizedDifference([\"sur_refl_b02\", \"sur_refl_b01\"]).rename(\"ndvi\")\n",
    "\n",
    "    # add ndvi band and apply mask\n",
    "    return image.addBands(ndvi).updateMask(mask).copyProperties(image,[\"system:time_start\",\"system:time_end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjL8NrlUess9"
   },
   "outputs": [],
   "source": [
    "# Load MODIS lst image collection\n",
    "# filter by date and apply preprocessing\n",
    "modis_lst = ee.ImageCollection(\"MODIS/006/MYD11A2\").filterDate(start_time,end_time).map(lst_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5uKwzh10UPf"
   },
   "outputs": [],
   "source": [
    "# Load MODIS surface reflectance image collection\n",
    "# filter by date and apply preprocessing\n",
    "modis_sr = ee.ImageCollection(\"MODIS/061/MOD09GQ\").filterDate(start_time, end_time).map(sr_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V-0ZjIIH3dl"
   },
   "outputs": [],
   "source": [
    "# import the CHIRPS dataset\n",
    "chirps = ee.ImageCollection(\"UCSB-CHG/CHIRPS/PENTAD\")\n",
    "\n",
    "# no filtering or preprocessing needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_n5XvDU0x8O"
   },
   "outputs": [],
   "source": [
    "# load static images for the model\n",
    "\n",
    "# load in a soil classification\n",
    "soil_class = ee.Image(\"OpenLandMap/SOL/SOL_TEXTURE-CLASS_USDA-TT_M/v02\").select([\"b0\"],[\"surface_soil_class\"])\n",
    "\n",
    "# load in DEM\n",
    "dem = ee.Image(\"USGS/GTOPO30\").select(\"elevation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw5mdrTGeTRp"
   },
   "source": [
    "Finally we have all of our features needed for training a model, next we need information on what the observed/modeled soil moisture is. Here we will use the [NASA-USDA Enhanced SMAP Global Soil Moisture Data](https://developers.google.com/earth-engine/datasets/catalog/NASA_USDA_HSL_SMAP10KM_soil_moisture) which is a combination of observed and modeled soil moisture ([Bolton and Crow, 2012](https://doi.org/10.1029/2012GL053470))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsOYH9_Z5Vgh"
   },
   "outputs": [],
   "source": [
    "# load in the soil moisture dataset\n",
    "soil_moisture = ee.ImageCollection(\"NASA_USDA/HSL/SMAP10KM_soil_moisture\").filterDate(start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMrUYnU36zmi"
   },
   "source": [
    "### Co-locating datasets using joins\n",
    "\n",
    "Now that we have all of our data, we need to store it in a manner to where we can use to together. Since we need to sample all of the data at the same time, we will need an image with all of the bands. Getting all of the bands together is not trivial because we need obserations at the same time. To efficiently gather all fo the data we need in one place we will use [joins](https://developers.google.com/earth-engine/guides/joins_intro) which combine elements from different collections.\n",
    "\n",
    "The other way to combine elements is to map over the collections and apply filters but that may not scale to large image collections very well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhLTSIpkfpP0"
   },
   "source": [
    "We are mostly concerned with temporal filters/joins, so we will need to define a filter to identify which elements we should join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gqTgFnL6yhy"
   },
   "outputs": [],
   "source": [
    "# Define an allowable time difference: one days in milliseconds.\n",
    "one_day_millis = 24 * 60 * 60 * 1000\n",
    "\n",
    "# Create a time filter to define a match as overlapping timestamps.\n",
    "time_filter = ee.Filter.Or(\n",
    "    # use max difference filter to specify only one day difference\n",
    "    # checks one day on either side of observation\n",
    "    ee.Filter.maxDifference(\n",
    "        difference= one_day_millis,\n",
    "        leftField= 'system:time_start',\n",
    "        rightField= 'system:time_end'\n",
    "    ),\n",
    "    ee.Filter.maxDifference(\n",
    "        difference= one_day_millis,\n",
    "        leftField='system:time_end',\n",
    "        rightField= 'system:time_start'\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMSDGHGmf9yI"
   },
   "source": [
    "Now that we have a filter, we need to define our join. This specifies what the results will be so we know what to look for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTdknOH26vep"
   },
   "outputs": [],
   "source": [
    "# Define the join.\n",
    "# this is \"saveBest\" which will give us the image closest in time to what we want\n",
    "ndvi_join = ee.Join.saveBest(\n",
    "  matchKey= 'ndvi', # this will be the name of the result in the collection\n",
    "  measureKey= 'timeDiff'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAkdPAcIgPGb"
   },
   "source": [
    "Lastly, we need to apply the join!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4BJnczcgOgy"
   },
   "outputs": [],
   "source": [
    "# Apply the join.\n",
    "# uses soil_moisture as the collection to join to and applies filter on surface reflectance data\n",
    "sm_ndvi = ndvi_join.apply(soil_moisture, modis_sr, time_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zp6q5rZ6vlr"
   },
   "outputs": [],
   "source": [
    "# check our result to see if it worked\n",
    "sm_ndvi.first().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJHLDQzRglsV"
   },
   "source": [
    "Now that we have verified that the join worked, we can do the same for the other collections. Here we define the join for the LST data and apply.\n",
    "\n",
    "Note: we apply the join on the result of the last join so we can keep things together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDW_E5g38bZP"
   },
   "outputs": [],
   "source": [
    "# Define the join.\n",
    "lst_join = ee.Join.saveBest(\n",
    "  matchKey= 'lst',\n",
    "  measureKey= 'timeDiff'\n",
    ")\n",
    "\n",
    "# Apply the join.\n",
    "sm_ndvi_lst = lst_join.apply(sm_ndvi, modis_lst, time_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YbPKQj_g8_d"
   },
   "source": [
    "We are going to mix things up for joining the precipitation data. Theoretically, precipitation can affect soil moisture days after a rain event. So, we want to account for that and do so with a different filter. We will check for the difference from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkS0LxGVIwuG"
   },
   "outputs": [],
   "source": [
    "# specify number of days we want to keep\n",
    "lag_days = 15\n",
    "\n",
    "# create our filter which keeps last n days of observations\n",
    "lag_filter = ee.Filter.And(\n",
    "    # filter for difference from observation on either side\n",
    "    ee.Filter.maxDifference(\n",
    "        difference= 1000 * 60 * 60 * 24 * lag_days,\n",
    "        leftField= \"system:time_start\",\n",
    "        rightField= \"system:time_start\"\n",
    "    ),\n",
    "    # filters data that is greater than the observation\n",
    "    # so we only keep days before obs\n",
    "    ee.Filter.greaterThan(\n",
    "        leftField= \"system:time_start\",\n",
    "        rightField= \"system:time_start\"\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRhimdBBh7mx"
   },
   "source": [
    "Now we have our fun filter than checks for days before observation. Now we want to apply but keep all of the observations. This way we can calculate the sum for the days leading up. To do so, we define the `saveAll` join and apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Th2r2XpPJUQK"
   },
   "outputs": [],
   "source": [
    "# save all join to save every image that meets out criteria\n",
    "lag_join = ee.Join.saveAll(\n",
    "    matchesKey= 'precip',\n",
    "    measureKey= 'delta_t',\n",
    "    ordering= \"system:time_start\",\n",
    "    ascending= True, # Sort chronologically\n",
    ")\n",
    "\n",
    "# Apply the join.\n",
    "sm_ndvi_lst_precip = lag_join.apply(sm_ndvi_lst, chirps, lag_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXqzCuGX-6Ky"
   },
   "outputs": [],
   "source": [
    "# apply filter for null values in join properties \n",
    "# just to ensure we don't have any missing data\n",
    "sm_ndvi_lst_precip  = sm_ndvi_lst_precip.filter(\n",
    "    ee.Filter.And(\n",
    "        ee.Filter.neq(\"ndvi\",None),\n",
    "        ee.Filter.neq(\"lst\",None),\n",
    "        ee.Filter.neq(\"precip\",None),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UNOe7bnERup"
   },
   "outputs": [],
   "source": [
    "# recast to image collection\n",
    "# sometimes with joins/filters it gets converted to a ee.Collection\n",
    "# so we just want to make sure EE knows it has images\n",
    "sm_ndvi_lst_precip = ee.ImageCollection(sm_ndvi_lst_precip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiMtbzV6a_sz"
   },
   "source": [
    "### Sampling data\n",
    "\n",
    "In the final collection from the co-locating process, there are the soil moisture images with the NDVI, LST, and precipitation data as properties. We want to sample points from the data to then get a dataset for machine learning.\n",
    "\n",
    "This is a little complex because there is not just one soil moisture observation to sample but mulitple in time. So, we will get all available dates to sample from, pick a few, and then sample from those iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWeq3Da-8pP8"
   },
   "outputs": [],
   "source": [
    "# get a list of dates to sample from\n",
    "dates = sm_ndvi_lst_precip.aggregate_array(\"system:time_start\").getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypBiaxIP_f_b"
   },
   "outputs": [],
   "source": [
    "# specify the number of dates we would like to sample\n",
    "n_days = 50\n",
    "\n",
    "# randomly select n dates to sample\n",
    "sample_dates = np.random.choice(dates,size=n_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVJR3EhBkSdg"
   },
   "source": [
    "We now have dates that we would like to sample, now we define a geographic region to sample. Here we will sample over all of CONUS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldqnpBAh-dXu"
   },
   "outputs": [],
   "source": [
    "# this loads in a global vector file of countries\n",
    "# filter by country of interest\n",
    "conus = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\").filter(\n",
    "    ee.Filter.eq(\"country_na\",\"United States\")\n",
    ")\n",
    "\n",
    "# get a simple bounding box\n",
    "sample_region = conus.geometry(1e4).bounds(1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPCWYu15kdiJ"
   },
   "source": [
    "Now we are ready to sample! We will loop through the randomly selected dates, grab our image for that date, combine all of the bands together, and then finally sample.\n",
    "\n",
    "We are using a for loop here to queue up multiple requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVQv1pys8ymo"
   },
   "outputs": [],
   "source": [
    "# define empty feature collection to append samples to\n",
    "training_samples = ee.FeatureCollection([])\n",
    "\n",
    "# loop over our dates\n",
    "for i,date in enumerate(sample_dates):\n",
    "    # get a time range to filter for date\n",
    "    t1 = ee.Date(int(date))\n",
    "    t2 = t1.advance(1,\"day\")\n",
    "\n",
    "    # get our image for date\n",
    "    img = ee.Image(sm_ndvi_lst_precip.filterDate(t1,t2).first())\n",
    "\n",
    "    # combine all of the images from joins into one with multiple bands\n",
    "    # notice we are fetching the property we specified in the join\n",
    "    # we also add our static images (soil class and DEM) to each image \n",
    "    img = (\n",
    "        img\n",
    "        .addBands(img.get(\"ndvi\")) # add ndvi\n",
    "        .addBands(img.get(\"lst\")) # add lst\n",
    "        # get precip as collecition and reduce to image\n",
    "        .addBands(ee.ImageCollection.fromImages(img.get('precip')).sum()) \n",
    "        # add static bands\n",
    "        .addBands(soil_class)\n",
    "        .addBands(dem)\n",
    "    )\n",
    "\n",
    "    # run sampling\n",
    "    samples = img.sample(\n",
    "        region = sample_region,\n",
    "        numPixels = 200, \n",
    "        scale = 10000,\n",
    "        seed = i,\n",
    "    )\n",
    "\n",
    "    # append samples to collection\n",
    "    training_samples = training_samples.merge(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUDC9oPv-0K2"
   },
   "outputs": [],
   "source": [
    "# check total number of sample\n",
    "training_samples.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oDTgywG_5F8"
   },
   "outputs": [],
   "source": [
    "# check to make sure our features have all of the information we want\n",
    "training_samples.first().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2Xt1V0nbInX"
   },
   "source": [
    "### Training/testing the model\n",
    "\n",
    "Now that we have our training data, we are ready to train a model. We will do a similar approach where we split the data into testing and training and do a quick check on how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4q1wBrGAL9h"
   },
   "outputs": [],
   "source": [
    "# specify which bands will be used as features and which one will be the label\n",
    "features = [\"ndvi\",\"LST_Day_1km\",\"elevation\",\"precipitation\",\"surface_soil_class\"]\n",
    "\n",
    "label = \"ssm\" # surface soil moisture in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDnzxS4RAjG8"
   },
   "outputs": [],
   "source": [
    "# add a random column to the collection to randomly split\n",
    "training_samples = training_samples.randomColumn(seed=5)\n",
    "\n",
    "# split into train/test datasets using 70-30 split\n",
    "training = training_samples.filter(ee.Filter.lte(\"random\", 0.7))\n",
    "testing = training_samples.filter(ee.Filter.gt(\"random\", 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3GlXFEtAypm"
   },
   "outputs": [],
   "source": [
    "# instantiate our model and train\n",
    "# note here we set the output to regression so it knows how to handle the outputs\n",
    "rf = (\n",
    "    ee.Classifier.smileRandomForest(numberOfTrees=50, bagFraction=0.8)\n",
    "    .setOutputMode(\"REGRESSION\")\n",
    "    .train(training, label, features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smZvBPyvBTax"
   },
   "outputs": [],
   "source": [
    "# apply model on test dataset\n",
    "y_test = testing.classify(rf, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPUg5wedBa71"
   },
   "outputs": [],
   "source": [
    "# get the predicted and observed values\n",
    "y_pred = np.array(y_test.aggregate_array(\"test\").getInfo())\n",
    "y_true = np.array(y_test.aggregate_array(label).getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZgHs9jhBnv0"
   },
   "outputs": [],
   "source": [
    "# make a quick scatter plot of the results\n",
    "plot(y_pred,y_true, \"C0o\",alpha=0.3)\n",
    "plot([0,25],[0,25],\"k--\")\n",
    "\n",
    "xlabel(\"Predicted Soil Moisture [mm]\")\n",
    "ylabel(\"Observed Soil Moisture [mm]\")\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UHoudsBCDgB"
   },
   "outputs": [],
   "source": [
    "# calculate RMSE quickly\n",
    "rmse = np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSS3FRoRCvaz"
   },
   "source": [
    "### Apply the model\n",
    "\n",
    "Let's assume we are very happy with our model and we now would like to apply it to our whole collection. To do so is pretty straightforward: we will define a function to map over the whole image collection, combine the bands, and apply the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppK9lVzeCykz"
   },
   "outputs": [],
   "source": [
    "# define function that applies model inference to image\n",
    "def apply_model(img):\n",
    "    # combine all of the images from joins into one with multiple bands\n",
    "    # notice we are fetching the property we specified in the join\n",
    "    # we also add our static images (soil class and DEM) to each image \n",
    "    img = (\n",
    "        img\n",
    "        .addBands(img.get(\"ndvi\")) # add ndvi\n",
    "        .addBands(img.get(\"lst\")) # add lst\n",
    "        # get precip as collecition and reduce to image\n",
    "        .addBands(ee.ImageCollection.fromImages(img.get('precip')).sum()) \n",
    "        # add static bands\n",
    "        .addBands(soil_class)\n",
    "        .addBands(dem)\n",
    "    )\n",
    "\n",
    "    # apply inference\n",
    "    pred = img.classify(rf,label+\"_pred\")\n",
    "\n",
    "    # return the image now with the estimate high resolution soil moisture\n",
    "    return img.addBands(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n26uPyowCttz"
   },
   "outputs": [],
   "source": [
    "# apply the prediction to the image collection\n",
    "sm_ndvi_lst_rf = sm_ndvi_lst_precip.map(apply_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-UquTS9DaWC"
   },
   "outputs": [],
   "source": [
    "# extract out one image for use to visually inspect\n",
    "view_img = sm_ndvi_lst_rf.first()#.clip(sample_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRlZc4BTz12C"
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(sample_region, 5)\n",
    "\n",
    "Map.addLayer(sample_region, {}, 'UT')\n",
    "\n",
    "\n",
    "Map.addLayer(view_img.select(\"ndvi\"),{\"min\":0,\"max\":1,\"palette\":cmaps.get_palette(\"viridis\")},\"NDVI\");\n",
    "Map.addLayer(view_img.select(\"LST_Day_1km\"),{\"min\":-5,\"max\":30,\"palette\":cmaps.get_palette(\"inferno\")},\"LST\");\n",
    "Map.addLayer(view_img.select(label),{\"min\":0,\"max\":25,\"palette\":cmaps.get_palette(\"plasma_r\")},\"Original SM\");\n",
    "Map.addLayer(view_img.select(label+\"_pred\"),{\"min\":0,\"max\":25,\"palette\":cmaps.get_palette(\"plasma_r\")},\"Downscaled SM\");\n",
    "\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOymWqC0gh5WLoz6rdIY2FG",
   "collapsed_sections": [],
   "name": "Lab 13 - Remote sensing of soil moisture.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
